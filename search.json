[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Remote Sensing - Learning Diary",
    "section": "",
    "text": "Welcome\nThis is my learning diary for the CASA0023 Remotely Sensing Cities an Environments module. Firstly, let’s talk a bit about myself and my background."
  },
  {
    "objectID": "index.html#personal-introduction",
    "href": "index.html#personal-introduction",
    "title": "CASA0023 Remote Sensing - Learning Diary",
    "section": "Personal Introduction",
    "text": "Personal Introduction\nHi! I’m Paul and I am a part-time degree apprenticeship student. I have a strong GIS background spanning nearly 20 years but with very little working experience with remote sensing.\nMost of my working life spent has been in Local Government and I am currently the GIS Administrator for the London Borough of Camden. I have predominantly used proprietary GIS software such as MapInfo, ArcGIS and Cadcorp. In more recent years I have also been using QGIS.\nIn terms of remote sensing, myself and especially Camden are very new to how this can shape decision making and policy. In the 2023/24 we took part in an Earth Observation Pilot scheme run by the Geospatial Commission and supported by AirBus. However, at the time we did not have the necessary skills, knowledge or software to really make full use of this pilot. If only this course started a year earlier!!\nDespite this lack of knowledge, the GIS Team did manage to use some EO data to build a site suitability model for Urban Greening locations (although my personal input was limited to support and project management). The main limitation we had in using the EO data available was that the technical aspects were conducted between QGIS and ArcGIS Pro (with an advanced licence and all spatial extensions). As such the workflow is not reproducible and therefore limited to a snapshot in time especially as access to the EO data was withdraw at the end of the pilot.\nIn January 2025 Camden have been invited to take part in a new EO Data Hub pilot which will provide more constant and consistent temporal and spatial resolution data. The exact details of the products included are not yet known but should fit very nicely into the topics learnt in the Remote Sensing Cities and Environment module as well as the Building Spatial Applications with Big Data module.\nMy overall aims for this module are to be able to successfully process and analyse EO data using best practice techniques with the key being that they are reproducible techniques. These can then be used as a new decision making and policy making tool for the London Borough of Camden as this is an area that has never been explored at Camden and is rarely explored in Local Government in general."
  },
  {
    "objectID": "intro.html#sec-summary",
    "href": "intro.html#sec-summary",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nAs a relative newbie to Remote Sensing there was so much new information this week that it’s very difficult to choose even a few things to talk about without writing an whole essay. Therefore I have decided that the best way to summarise this would be through a mind map Figure 1.1.\n\n\n\nFigure 1.1: Introduction to Remote Sensing Mind map\n\n\nThere is so much information that could be discussed here but I’d like to focus on the bands. Images produced at different bands are what makes up the creation of useful and relevant images. Personally I have previously attempted to use earth observation data without understanding the differences between the bands and this made the task at hand incredibly difficult and mainly involved mindlessly following guides and videos just to get a semi-readable output. So this weeks introduction to remote sensing really helped me to understand what bands relate to which information on the ground. And importantly how the different bands can be combined depending on the purpose of any analysis."
  },
  {
    "objectID": "intro.html#sec-application",
    "href": "intro.html#sec-application",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nThere are numerous applications for remote sensing which have been discussed widely in many articles. Just by searching scholarly articles published in just the past month for the term “remote sensing”, hundreds of articles are returned. By scanning the first few pages articles ranging from fire monitoring, wheat yield prediction, military and flooding are evident. Also, the number of different landscapes that can be monitored are also highly evident, including polar regions, mountains, wetlands, cities, forests and agricultural land.\nWhilst many of the use cases available are fascinating, as this is an introduction to remote sensing it would be easy to get lost in the array of use cases on offer. As such I have instead decided to focuses on a comparison between Landsat-8 and Sentinel-2. There are still a huge amount of articles to consider in this topic, many again with very different use cases however I will consider two more general comparison articles.\n\n1.2.1 Prelimary Sentinel-2 and Landsat 8 Comparison\nDespite the many variables in sensor technology it is possible to compare imagery from Landsat-8 and Sentinel-2 due to an overlap in the bands captured by each. Mandanici and Bitelli (2016) prepared an initial comparison approximately a year after Sentinel-2 was launched in 2015. Landsat-8 was launched in 2013.\nMandanici and Bitelli begin with a basic summary of the sensor which provides useful context for their comparison which summarised in Table 1.1.\n\n\n\n\nTable 1.1: Summary comparison of basic Landsat-8 and Sentinel-2 specifications\n\n\nSatellite\nSpatialResolution\nSwathWidth\nRevisitTime\nSensor\nNumberOfBands\nComparableBands\n\n\n\n\nLandsat-8\n30m\n185km\nOperational Land Imager (OLI)\n16 days\n11\nblue: 485 nm, green: 563 nm, red: 655 nm, NIR: 865 nm, short-wave infrared 1 (SWIR1): 1610 nm, SWIR2: 2200 nm\n\n\nSentinel-2\nup to 10m\n290km\nMultispectral Instruments (MSI)\n5 days\n13\nblue: 490 nm, green: 560 nm, red: 665 nm, NIR: 842 nm, SWIR1: 1910 nm, and SWIR2: 2190 nm\n\n\n\n\n\n\n\n\nSix sites across the Earth were chosen to compare Sentinel/Landsat images, the sites were chosen to provide a mix of land cover types and climatic conditions, the comparison images were taken on the same day to build as close a comparison as possible. Correlation and regression coefficients were then calculated across the bands for the study areas.\nFrom my currently limited remote sensing knowledge I found this methodology difficult to follow due to it’s highly mathematical model, however the overall results showed there was a very good correlation between the corresponding bands. Although limitations were identified including radiometric differences requiring careful evaluation and investigating discrepancies in reflectance values relevance.\n\n\n1.2.2 Comparison using Google Earth Engine\nThe article by Nasiri et al. (2022) was chosen due to it’s more contemporary nature providing a useful and relevant comparison against the preliminary comparison. A further advantage of reviewing this research was it’s methodology of using Google Earth Engine (GEE). We will begin using Google Earth Engine later in the course so it seemed even more appropriate to use this paper.\nThe specific methodology for comparing Landsat-8 and Sentinel-2 involved producing time-series analysis of a single study area (Tehran Province, Iran) using images from both satellites. As the resolutions did not match the MSI data was downsampled to the match that of OLI.\nThe first output was a range of comparison images Figure 1.2 which help demonstrate how difficult it is for the human eye to identify variations in accuracy of this level of data.\n\n\n\nFigure 1.2: Landsat-8 and Sentinel-2 image comparison - using False-colour images (R: NIR, G:red, B: green) across seasons: (a) Spring, (b) Summer and (c) Autumn\n\n\nThe second output was more in-depth evaluation\n\n\n1.2.3 Review\nDespite lacking some knowledge around the specific calculations in the analysis and found these to be two very interesting articles. The comparison between the methodologies is quite clear with Nasiri et al. (2022) being easier to follow mainly due to it’s use of more visual representation of the data.\nThe methodology for Mandanici and Bitelli (2016) appears to be a lot less reproducible as there is less detail in this section, it also does not refer to which languages, applications, etc. that were used. Nasiri on the otherhand was more reproducible due to it’s use of Google Earth Engine which has the added bonus of avoiding local storage issues and providing greater computing power for analysis and processing (Carrasco et al. 2019). This may just be due to the fact that Google Earth Engine wasn’t as widely used or known in 2016 as it is was 2022.\nThe main limitations I see with both articles if that the number of samples used was quite low and therefore it cannot be said with absolute certainty whether the results would be replicated in other areas. Mandanici does look at multiple sites but they are chosen for their differing landscapes and climate. Nasiri on the other hand only uses one sample area but with clearly distinguished land uses, Whilst this is useful as it identified variations in accuracy across land uses (artificial land 95-100%, bare earth 71-86%) it is not clear whether similar results would be expected in other areas of interest."
  },
  {
    "objectID": "intro.html#sec-refection",
    "href": "intro.html#sec-refection",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nBoth articles discussed in Section 1.2 provide a good overview of both Landsat-8 and Sentinel-2 which helps to consolidate some of the topics taught in class this week. Especially in relation to how different bands can be used for different purposes. This will be extremely useful in the coming months as we look at our own analysis in this course and in CASA0025, but also as part of work as we begin to use a new Earth Observation Data Hub.\nSome of the methodology of both papers is still difficult for me to process, particularly around the specific analysis and calculations, but hopefully this is because it is still the first week of remote sensing. However reading these articles really helped my understanding of the use cases of both satellites and specifically their similiarities and importantly how the spectral resolution of the same bands have slight variations to be aware of. Also understanding how bands, can be combined in different ways and in different applications to produce similar images for analysis. This then helps to provide even more comparable images across a larger temporal scale as any gaps in imagery (possibly due to constraints such as scattering and in particular cloud cover) from one satellite may be able to be filled by the other.\nAnother topic I would have liked to explore is the effect that different types of scattering has on the images captured and how any pre-processing by the agencies responsible for the data affects the images that we see.\n\n\n\n\nCarrasco, Luis, Aneurin W. O’Neil, R. Daniel Morton, and Clare S. Rowland. 2019. “Evaluating Combinations of Temporally Aggregated Sentinel-1, Sentinel-2 and Landsat 8 for Land Cover Mapping with Google Earth Engine.” Remote Sensing 11 (3, 3): 288. https://doi.org/10.3390/rs11030288.\n\n\nMandanici, Emanuele, and Gabriele Bitelli. 2016. “Preliminary Comparison of Sentinel-2 and Landsat 8 Imagery for a Combined Use.” Remote Sensing 8 (12, 12): 1014. https://doi.org/10.3390/rs8121014.\n\n\nNasiri, Vahid, Azade Deljouei, Fardin Moradi, Seyed Mohammad Moein Sadeghi, and Stelian Alexandru Borz. 2022. “Land Use and Land Cover Mapping Using Sentinel-2, Landsat-8 Satellite Images, and Google Earth Engine: A Comparison of Two Composition Methods.” Remote Sensing 14 (9, 9): 1977. https://doi.org/10.3390/rs14091977."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Abburu, Sunitha, and Suresh Babu Golla. 2015. “Satellite\nImage Classification Methods and Techniques:\nA Review.” International Journal of Computer\nApplications 119 (8): 20–25. https://doi.org/10.5120/21088-3779.\n\n\nAlmeida, Cátia Rodrigues de, Ana Cláudia Teodoro, and Artur Gonçalves.\n2021. “Study of the Urban Heat Island\n(UHI) Using Remote Sensing\nData/Techniques: A Systematic\nReview.” Environments 8 (10, 10): 105. https://doi.org/10.3390/environments8100105.\n\n\nAmalisana, Birohmatin, Rokhmatullah, and Revi Hernina. 2017. “Land\nCover Analysis by Using Pixel-Based and\nObject-Based Image Classification Method in\nBogor.” IOP Conference Series: Earth and\nEnvironmental Science 98 (1): 012005. https://doi.org/10.1088/1755-1315/98/1/012005.\n\n\nAmani, Meisam, Arsalan Ghorbanian, Seyed Ali Ahmadi, Mohammad Kakooei,\nArmin Moghimi, S. Mohammad Mirmazloumi, Sayyed Hamed Alizadeh Moghaddam,\net al. 2020. “Google Earth Engine Cloud Computing\nPlatform for Remote Sensing Big Data Applications:\nA Comprehensive Review.” IEEE Journal of\nSelected Topics in Applied Earth Observations and Remote Sensing\n13: 5326–50. https://doi.org/10.1109/JSTARS.2020.3021052.\n\n\nBarsi, Julia A., Bahjat Alhammoud, Jeffrey Czapla-Myers, Ferran Gascon,\nMd. Obaidul Haque, Morakot Kaewmanee, Larry Leigh, and Brian L. Markham.\n2018. “Sentinel-2A MSI and Landsat-8 OLI\nRadiometric Cross Comparison over Desert Sites.” European\nJournal of Remote Sensing 51 (1): 822–37. https://doi.org/10.1080/22797254.2018.1507613.\n\n\nBBC. 2022. “Undeclared Pools in France Uncovered by\nAI Technology.” BBC News: Europe, August\n29, 2022. https://www.bbc.com/news/world-europe-62717599.\n\n\nBernardo, Nariane, Fernanda Watanabe, Thanan Rodrigues, and Enner\nAlcântara. 2016. “An Investigation into the Effectiveness of\nRelative and Absolute Atmospheric Correction for Retrieval the\nTSM Concentration in Inland Waters.” Modeling\nEarth Systems and Environment 2 (3): 114. https://doi.org/10.1007/s40808-016-0176-9.\n\n\nCarrasco, Luis, Aneurin W. O’Neil, R. Daniel Morton, and Clare S.\nRowland. 2019. “Evaluating Combinations of\nTemporally Aggregated Sentinel-1, Sentinel-2\nand Landsat 8 for Land Cover Mapping with\nGoogle Earth Engine.” Remote Sensing 11 (3,\n3): 288. https://doi.org/10.3390/rs11030288.\n\n\nEOS Data Analytics. 2025. “Satellite Band\nCombinations: Analytical Methods For\nImagery.” 2025. https://eos.com/make-an-analysis/.\n\n\nESRI. 2025. “GIS Dictionary.” 2025. https://support.esri.com/en-us/gis-dictionary.\n\n\nFlores, Africa, K. Herndon, Rajesh Thapa, and Emil Cherrington. 2019.\n“Synthetic Aperture Radar (SAR)\nHandbook: Comprehensive Methodologies for\nForest Monitoring and Biomass\nEstimation.” https://doi.org/10.25966/NR2C-S697.\n\n\nFoody, Giles M. 2002. “Status of Land Cover Classification\nAccuracy Assessment.” Remote Sensing of Environment 80\n(1): 185–201. https://doi.org/10.1016/S0034-4257(01)00295-4.\n\n\nGISGeography. 2014. “Image Classification Techniques\nin Remote Sensing.” GIS Geography. May 2, 2014. https://gisgeography.com/image-classification-techniques-remote-sensing/.\n\n\n———. 2015. “What Is Atmospheric Correction in\nRemote Sensing?” GIS Geography. November 7, 2015. https://gisgeography.com/atmospheric-correction/.\n\n\n———. 2016. “Supervised and Unsupervised\nClassification in Remote Sensing.” GIS\nGeography. June 30, 2016. https://gisgeography.com/supervised-unsupervised-classification-arcgis/.\n\n\nGlobal Land Discovery and Analysis. n.d. “Global Forest\nChange.” Accessed March 2, 2025. https://glad.earthengine.app/view/global-forest-change#bl=off;old=off;dl=1;lon=20;lat=10;zoom=3;\n\n\nGonzales, Jenny. 2019. “How a Sheriff in Brazil Is\nUsing Satellites to Stop Deforestation.” Mongabay Environmental\nNews. April 12, 2019. https://news.mongabay.com/2019/04/how-a-sheriff-in-brazil-is-using-satellites-to-stop-deforestation/.\n\n\nGoogle. 2024. “About Google Earth Engine.”\nGoogle for Developers. 2024. https://developers.google.com/earth-engine/guides.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David\nThau, and Rebecca Moore. 2017. “Google Earth Engine:\nPlanetary-scale Geospatial Analysis for\nEveryone.” Remote Sensing of Environment, Big\nRemotely Sensed Data: Tools, applications and experiences,\n202 (December): 18–27. https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nGreater London Authority. 2024a. “Air Quality\nMonitoring - Diffusion Tube Results - London\nDatastore.” https://data.london.gov.uk/dataset/air-quality-monitoring-diffusion-tube-results.\n\n\n———. 2024b. “Green Cover Map.” GLA\nIntelligence; Analysis Unit. 2024. https://apps.london.gov.uk/green-cover.\n\n\n———. 2025. “Parks and Green Spaces | London City\nHall.” 2025. https://www.london.gov.uk/programmes-strategies/environment-and-climate-change/parks-green-spaces-and-biodiversity/parks-and-green-spaces.\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A.\nTyukavina, D. Thau, et al. 2013. “High-Resolution Global\nMaps of 21st-Century Forest Cover Change.”\nScience 342 (6160): 850–53. https://doi.org/10.1126/science.1244693.\n\n\nHu, Yong, Liangyun Liu, Lingling Liu, and Quanjun Jiao. 2011.\n“Comparison of Absolute and Relative Radiometric Normalization Use\nLandsat Time Series Images.” In\nMIPPR 2011: Remote Sensing Image\nProcessing, Geographic Information Systems, and Other Applications,\nedited by Faxiong Zhang and Faxiong Zhang, 8006:800616. SPIE /\nInternational Society for Optics and Photonics. https://doi.org/10.1117/12.902076.\n\n\nIrons, James R, and Gary W Petersen. 1981. “Texture Transforms of\nRemote Sensing Data.” Remote Sensing of Environment 11\n(January): 359–70. https://doi.org/10.1016/0034-4257(81)90033-X.\n\n\nJaadi. 2024. “Principal Component Analysis\n(PCA) Explained.” Built In. 2024. https://builtin.com/data-science/step-step-explanation-principal-component-analysis.\n\n\nKumar, Lalit, and Onisimo Mutanga. 2018. “Google Earth\nEngine Applications Since Inception: Usage,\nTrends, and Potential.” Remote\nSensing 10 (10, 10): 1509. https://doi.org/10.3390/rs10101509.\n\n\nLB Camden, LB Islington, UDL. 2024. “Green\nInfrastructure for Streets A Paractical Guide\nto Design, Delivery & Maintenance.” UDL. 2024. https://www.urbandesignlearning.com/resources/publications/details?recordId=recVcJedUUe7jlA6E.\n\n\nLi, Xun, Wendy Y. Chen, Giovanni Sanesi, and Raffaele Lafortezza. 2019.\n“Remote Sensing in Urban Forestry:\nRecent Applications and Future\nDirections.” Remote Sensing 11 (10, 10): 1144. https://doi.org/10.3390/rs11101144.\n\n\nLondon Borough of Camden. 2024. “Earth Observation\nPilot.” ArcGIS StoryMaps. June 27, 2024. https://storymaps.arcgis.com/stories/2cb162d9c7984d47b5545322ca5b4ea2.\n\n\nMandanici, Emanuele, and Gabriele Bitelli. 2016. “Preliminary\nComparison of Sentinel-2 and\nLandsat 8 Imagery for a Combined\nUse.” Remote Sensing 8 (12, 12): 1014. https://doi.org/10.3390/rs8121014.\n\n\nMastro, Pietro, Guido Masiello, Carmine Serio, and Antonio Pepe. 2022.\n“Change Detection Techniques with Synthetic\nAperture Radar Images: Experiments with Random\nForests and Sentinel-1 Observations.”\nRemote Sensing 14 (14, 14): 3323. https://doi.org/10.3390/rs14143323.\n\n\nMilillo, Pietro, Giorgia Giardina, Matthew J. DeJong, Daniele Perissin,\nand Giovanni Milillo. 2018. “Multi-Temporal InSAR Structural\nDamage Assessment: The London Crossrail Case\nStudy.” Remote Sensing 10 (2, 2): 287. https://doi.org/10.3390/rs10020287.\n\n\nNasiri, Vahid, Azade Deljouei, Fardin Moradi, Seyed Mohammad Moein\nSadeghi, and Stelian Alexandru Borz. 2022. “Land Use\nand Land Cover Mapping Using Sentinel-2, Landsat-8\nSatellite Images, and Google Earth Engine: A\nComparison of Two Composition Methods.”\nRemote Sensing 14 (9, 9): 1977. https://doi.org/10.3390/rs14091977.\n\n\nNielsen, Allan Aasbjerg. 2005. “AN ITERATIVE EXTENSION TO\nTHE MAD TRANSFORMATION FOR CHANGE DETECTION IN MULTI- AND HYPERSPECTRAL\nREMOTE SENSING DATA.”\n\n\n———. 2007. “The Regularized Iteratively Reweighted MAD\nMethod for Change Detection in Multi-\nand Hyperspectral Data.” IEEE Transactions on\nImage Processing 16 (2): 463–78. https://doi.org/10.1109/TIP.2006.888195.\n\n\nNorris, Gregory S., Armand LaRocque, Brigitte Leblon, Myriam A. Barbeau,\nand Alan R. Hanson. 2024. “Comparing Pixel- and\nObject-Based Approaches for Classifying Multispectral\nDrone Imagery of a Salt Marsh Restoration and\nReference Site.” Remote Sensing 16 (6, 6):\n1049. https://doi.org/10.3390/rs16061049.\n\n\nOffice of National Statistics. 2021. “Nomis - 2021 Census\nArea Profile - London Region.” 2021. https://www.nomisweb.co.uk/sources/census_2021/report?compare=E12000007.\n\n\nOlofsson, Pontus, Giles M. Foody, Martin Herold, Stephen V. Stehman,\nCurtis E. Woodcock, and Michael A. Wulder. 2014. “Good Practices\nfor Estimating Area and Assessing Accuracy of Land Change.”\nRemote Sensing of Environment 148 (May): 42–57. https://doi.org/10.1016/j.rse.2014.02.015.\n\n\nScheip, Corey M., and Karl W. Wegmann. 2021.\n“HazMapper: A Global Open-Source Natural Hazard\nMapping Application in Google Earth Engine.”\nNatural Hazards and Earth System Sciences 21 (5): 1495–1511. https://doi.org/10.5194/nhess-21-1495-2021.\n\n\nTransport for London. 2017. “Healthy Streets for\nLondon.”\n\n\nUSGS. 2024. “What Are the Best Landsat Spectral Bands\nfor Use in My Research? | U.S.\nGeological Survey.” March 19, 2024. https://www.usgs.gov/faqs/what-are-best-landsat-spectral-bands-use-my-research.\n\n\n———. 2025. “USGS Isis: Glossary.”\n2025. https://isis.astrogeology.usgs.gov/8.1.0/documents/Glossary/Glossary.html.\n\n\nVillalba, Fernando. 2023. “Please Kill RTFM!”\nMedium. July 6, 2023. https://nandovillalba.medium.com/platform-engineering-please-kill-rtfm-72de6f01075e.\n\n\nWellmann, Thilo, Angela Lausch, Erik Andersson, Sonja Knapp, Chiara\nCortinovis, Jessica Jache, Sebastian Scheuer, et al. 2020. “Remote\nSensing in Urban Planning: Contributions Towards\nEcologically Sound Policies?” Landscape and Urban\nPlanning 204 (December): 103921. https://doi.org/10.1016/j.landurbplan.2020.103921.\n\n\nWen, Yanfeng, Peng Chen, Zhenhua Zhang, and Yunzhou Li. 2024.\n“Cross-Attention-Based High Spatial-Temporal Resolution\nFusion of Sentinel-2 and Sentinel-3\nData for Ocean Water Quality Assessment.”\nRemote Sensing 16 (24, 24): 4781. https://doi.org/10.3390/rs16244781."
  },
  {
    "objectID": "2_portfolio.html",
    "href": "2_portfolio.html",
    "title": "2  Portfolio",
    "section": "",
    "text": "This week we discussed how to build our online portfolio using Quarto (web page) and Xarigan (presentation). This also included how to host pages through GitHub.\nOur main task this week was to build a presentation in Xarigan about a specific remote sensing satellite.\nI choose to create my presentation on the commercial satellite, Pleiades Neo, as I have a working knowledge of the imagery produced."
  },
  {
    "objectID": "3_data_corrections.html#sec-summary",
    "href": "3_data_corrections.html#sec-summary",
    "title": "3  Remote Sensing Data and Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nThis week we delved deeper into remote sensing topics particularly data corrections, joining and enhancements. Lots of new terms were raised and some of the concepts were challenging to understand so it’s easiest to summarise these terms by building a Table 3.1. A lot of these terms could have entire lectures dedicated to them so I attempt to put these into a simple terms as possible. Due to the large number of terms considered, ChatGPT was used to provide an initial sweep of terms and sources, then these were fact checked and more detail added where necessary. Sources include NASA, ESA, USGS, Landsat Science, ESRI and many of the sources listed in the references.\n\n\n\n\nTable 3.1: Glossary of remote sensing terminology\n\n\nTerm\nDescription\n\n\n\n\nRBV sensor\nReturn Beam Vidicon - A camera-based sensor used on early Landsat missions for capturing panchromatic images.\n\n\nMSS sensor\nMultispectral Scanner - The sensor onboard early Landsat satellites that captured data in several broad spectral bands.\n\n\nPush broom\nA type of sensor that uses linear arrays to capture imagery as the platform moves forward, capturing a swath in one go.\n\n\nWhisk broom\nA sensor that uses a mirror to scan the ground cross-track while capturing data one pixel at a time.\n\n\nScan Line Corrector\nDevice that compensates for motion distortions in satellite imagery caused by satellite movement.\n\n\nGeometric Correction\nThe process of correcting spatial distortions in remote sensing imagery to align with map coordinates. This is a similar process to that of paper maps being digitised and corrected to align with digitial representation of the Earth. It involves the use of ground control points identified on the captured image and a \"gold standard\" image, then using transformation algorithms to align the image.\n\n\nAtmospheric Correction\nRemoving the atmospheric effects (e.g., scattering, absorption) from data values to retrieve the surface reflectance. It is always recommended to use atmospheric correction as this removes hazing from images.\n\n\nDark Object Subtraction (DOS)\nA technique for atmospheric correction that finds the values of the darkest values and then subtracts the that from each pixel. Could also be termed hostogram adjustment.\n\n\nPseudo-invariant features (PIF)\nFeatures assumed to have stable reflectance over time. Examples include water bodies, rocky surfaces. Can be used for atmospheric correction, sensor callibration and change detection\n\n\nAtmospheric Radiative Transfer Models\nMathematical models used to simulate the interaction of light with the atmosphere. Commercial software available for atmospheric correction includes ACORN (Atmospheirc CORrection Now), FLAASH (Fast Line-of-Sight Atmospheric Analysis of Spectral Hypercubes), QUAC (Quick Atmospheric Correction) and ATCOR (Atmospheric Correction of Reflectance). Free software: SMAC (Simplified Model for Atmospheric Correction and Orfeo Toolb\n\n\nEmpirical Line Correction\nA method of atmospheric correction using ground-truth measurements to directly relate image data to reflectance values.\n\n\nField Spectrometer\nPortable instruments used to measure the spectral reflectance of materials in situ.\n\n\nPath Radiance\nThe portion of radiance reflected by the atmosphere e.g. scattering.\n\n\nAtmospheric attenuation\nThe atmospheric absorption of electromagnetic radiation due to materials in the atmosphere (e.g. water vapour, dust)\n\n\nOrthorectification or Topographic correction\nCorrecting distortions in imagery, making the pixels appear at nadair\n\n\nNadir / off-nadir\nNadir: directly beneath a sensor. Off-nadir: any angle except directly beneath the sensor.\n\n\nSolar Zentih\nThe angle between the sun and the vertical direction at a given location.\n\n\nSolar Azimuth\nThe angle of the sun, measured clockwise from the north. North = 0°, East = 90° at sunrise and 270° at sunset\n\n\nRadiometric Callibration\nThe process of converting the captured Digital Number to a radiance or reflectance values.\n\n\nDigital Number (DN)\nThe raw output value (with no units) recorded by a sensor, wuth each number indicating a range of colours, e.g. an 8 bit image has value 0 (black) to 255 (white). These represent the radiance or reflectance.\n\n\nRadiance\nRadiation that is leaving the Earth\n\n\nSurface Reflectance\nThe fraction of incoming light that a surface reflects, corrected to account for atmospheric effects and light source.\n\n\nIrradiance\nRadiation that is reaching the Earth such as from the Sun\n\n\nMosiacking\nThe process of combining multiple images into a single and seamless image.\n\n\nContrast Enhancement\nTechniques used to improve image visibility by increasing the contrast between features.\n\n\nBand ratioing\nDividing the pixel values of one spectral band by another to highlight specific features (e.g., vegetation indices).\n\n\nFiltering\nThe process of enhancing or suppressing specific spatial frequencies in an image.\n\n\nEdge enhancement\nTechniques to highlight boundaries and transitions in imagery.\n\n\nEmbossing\nAn image processing technique that simulates 3D surface relief.\n\n\nPrincipal Comonent Analysis (PCA)\nA statistical technique used to transform multi-spectral data by reducing the dimensions of the data whilst retaining the key information.\n\n\nTexture\nThe spatial variation in pixel values, representing surface roughness or pattern.\n\n\nImage fusion\nA subset of data fusion that focuses on merging images to improve resoluton. This can be used to combine certain Landsat and Sentinel images into a single working image.\n\n\nPan Sharpen\nA technique used to enhance the spatial resolution of multispectral images by combining them with a high resolution panchromatic image.\n\n\nData fusion\nThe process of combining data from multiple sources with the goal of improving accuracy and usefulness.\n\n\n\n\n\n\n\n\nAnother key point raised throughout the lecture was that regression plays a key part in many of the corrections that we looked into. This links back to (?sec-wk1-application) discussion were I initially found it difficult to understand some of the comparisons that were being made. So this lecture really helped to consolidate those comparison by clearly explaining the important role that regression plays in remote sensing."
  },
  {
    "objectID": "3_data_corrections.html#sec-applications",
    "href": "3_data_corrections.html#sec-applications",
    "title": "3  Remote Sensing Data and Corrections",
    "section": "3.2 Applications - Effectiveness of relative and absolute correction",
    "text": "3.2 Applications - Effectiveness of relative and absolute correction\nThere is almost endless possibilities to expand on in the topics covered this week so it’s a difficult job to focus on any one area. However, in week 1 I said that I’d like to investigate was atmospheric scattering therefore I will focus this section on atmospheric correction but also comparing against radiometric normalisation. This specifically looks at the differences and inaccuracy of relative and absolute correction.\n\n3.2.1 Bernardo et al. (2016)\nThe availability of absolute atmospheric correction inputs can be generalised over an area or season leading the potential accuracy issues. This is why Bernardo et al. (2016) investigated the effectiveness of an absolute atmospheric correction against a relative radiometric normalisation. Their study was specifically to estimate total suspended matter (TSM) concentrations in the Barra Bonita Hydroelectric Reservior, São Paulo however the general methodology could potentially be applied to other areas.\nThe reflectance errors were measured compared by assessing root mean squared error (RMSE) and the mean absolute percent error (MAPE). With a comparison made agaisnt the FLAASH (absolute method) against IRMAD - iteratively reweighted multivariate alteration detection (relative method) correction methods.\n\n\n\n\nTable 3.2: Reflectance errors from FLAASH and IRMAD corrections (bernando2016?)\n\n\nOLI band\nRMSE (%) FLAASH\nRMSE (%) IRMAD\nMAPE (%) FLAASH\nMAPE (%) IRMAD\n\n\n\n\nCoastal (440nm)\n133.45\n31.22\n131.45\n25.82\n\n\nBlue (480nm)\n53.70\n25.06\n51.73\n21.84\n\n\nGreen (560nm)\n11.50\n12.29\n9.61\n9.46\n\n\nRed (655nm)\n34.45\n20.03\n33.38\n16.98\n\n\nNIR (865nm)\n88.29\n49.97\n81.71\n45.37\n\n\n\n\n\n\n\n\nThe findings clearly show greater levels in inaccuracy from the absolute method (FLAASH) in both methods of comparison across nearly all bands. The only exception is the Green band’s RMSE percentage using the relative method (IRMAD). The percentage difference in correction methods for the coastal band of 131-133% (absolute) versus 25-31% (relative) is a staggering figure. It would have been really interesting to see other examples of this analysis to see if this is a general trend or just an anomaly for the area.\nThe authors do state various limitations to their study including the assumptions made in each methods potentially leading to errors themselves. This could be a good area for further investigations but what I’d really like to see is a similar paper comparing these methods in various locations to identify whether this is a general trend.\n\n\n3.2.2 Hu et al. (2011)\nWe have seen one example of a comparison between absolute and relative corrections but we shouldn’t just accept one study’s conclusion. We need to be more critical and if we can’t question findings ourselves through our own study then we can use other articles to help challenge or support these findings.\nSo I have picked a similar study with a similar methodology in Hu et al. (2011). I will focus on the key differences in the methodology but first let’s summarise the similarities:\n\ncompares using landsat images\ncompares a single study area using time series images\nuses FLAASH for absolute atmospheric correction\nuses multivariate alternative detection (MAD) for relative radiometric normalisation\n\nAlthough the use of MAD is similar to Bernardo et al. (2016)’s technique of iteratively reweighted MAD (IRMAD), it provides a more basic detection of change as it is a one-pass approach and does not iteratively refine the results, also IRMAD are much less noisy than MAD(Nielsen (2005), Nielsen (2007)). There is also a third approach, regularised IRMAD which can perform even better but this was not part of the studies being compared.\nDespite the differences in the relative correction calculations we can still review the results to help our comparison. Hu et al. (2011) used regression to assess the difference between absolute and relative corrections and the findings can be reviewed through the standard deviation results of each method.\n\n\n\n\nTable 3.3: Standard Deviation of the difference in each band for relative normalisation against atmospheric correction\n\n\nBand\nBand 1\nBand 2\nBand 3\nBand 4\nBand 5\nBand 7\n\n\n\n\nSTD of Relative Normalization\n0.0013\n0.0018\n0.0017\n0.0045\n0.0066\n0.0047\n\n\nSTD of Atmospheric Correction\n0.0025\n0.0030\n0.0033\n0.0086\n0.0083\n0.0074\n\n\n\n\n\n\n\n\nThe overall results show that both methods reduce radiometric distortion, but relative normalisation corrects it more effectively. This is shown by the lower standard deviations of relative normalisation versus atmospheric correction across all bands (?tbl-std-comparison).\n\n\n3.2.3 Review\nI suspect that whilst the papers talk about absolute corrections having high percentage error in certain bands that this could be specific to the location of the study and the assumptions made throughout. There are so many variables at play that it would be highly improbable to produce a study that could feasible review all of these aspects.\nIn an ideal world we would be able to say exactly what corrections and enhancements to apply to an image to provide the optimal output. However that is just not possible, if we think about the sheer amount of variables, including atmospheric conditions, topological factors, sensor differences, then we can begin to see why there is no simple set of tools for analysis.\nThis is evident in both the papers discussed and have previously seen in other papers. It could appear that the scope is quite limited as they focus on very small samples (Bernando - Barra Bonita Hydroelectric Reservior area, São Paulo; Hu et al - Yellow River Source, Eastern Tibet) for their analysis (previously discussed in week 1). However if we consider this from a technical point of view then simply the amount of computational power required to process much larger samples is very restrictive and time-consuming."
  },
  {
    "objectID": "3_data_corrections.html#sec-refection",
    "href": "3_data_corrections.html#sec-refection",
    "title": "3  Remote Sensing Data and Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nBefore reflecting on some of the more technical aspects discussed I think it’s first important to highlight the role that Virginia Norwood played in modern remote sensing. This was covered right at the beginning of the lecture and is quite an interesting story. A whole review could written about this but I think the fact the Virginia Norwood is known as the “mother of Landsat” says a great deal, and the full story of her life can be found in multiple articles including McClain (2023) and Inventors Hall of Fame (2025).\nSo back to the reflection, this week was definitely challenging, particularly with the amount of different terms, ideas and formulas raised. However when I really began to delve deeper into these concepts and particularly those discussed in Section 3.2 they really become clearer. You can really start to see the benefit these corrections and enhancements can have as part of wider studies.\nAs mentioned previously I’m looking forward to putting this ideas into practice through the Earth Observation Data Hub pilot scheme that Camden will soon have access to. I want to explore what data we will get access to and can finally understand the differences between products and particular what information can be derived from different bands. This will be a big improvement in the previous EO work that I’ve done which involved blindly following guides to try to get a result that seems similar.\nOne final note, even though it’s good to understand the processing required and it really helped boost my overall understanding of the challenges with remote sensing data, I’m so glad that most of the processing is already built into packages or in the Analysis Ready Data.\n\n\n\n\nBernardo, Nariane, Fernanda Watanabe, Thanan Rodrigues, and Enner Alcântara. 2016. “An Investigation into the Effectiveness of Relative and Absolute Atmospheric Correction for Retrieval the TSM Concentration in Inland Waters.” Modeling Earth Systems and Environment 2 (3): 114. https://doi.org/10.1007/s40808-016-0176-9.\n\n\nHu, Yong, Liangyun Liu, Lingling Liu, and Quanjun Jiao. 2011. “Comparison of Absolute and Relative Radiometric Normalization Use Landsat Time Series Images.” In MIPPR 2011: Remote Sensing Image Processing, Geographic Information Systems, and Other Applications, edited by Faxiong Zhang and Faxiong Zhang, 8006:800616. SPIE / International Society for Optics and Photonics. https://doi.org/10.1117/12.902076.\n\n\nInventors Hall of Fame. 2025. “Virginia Norwood | National Inventors Hall of Fame® Inductee.” January 31, 2025. https://www.invent.org/inductees/virginia-norwood.\n\n\nMcClain, Dylan Loeb. 2023. “Virginia Norwood, ‘Mother’ of Satellite Imaging Systems, Dies at 96.” The New York Times: Science, April 12, 2023. https://www.nytimes.com/2023/04/12/science/space/virginia-norwood-dead.html.\n\n\nNielsen, Allan Aasbjerg. 2005. “AN ITERATIVE EXTENSION TO THE MAD TRANSFORMATION FOR CHANGE DETECTION IN MULTI- AND HYPERSPECTRAL REMOTE SENSING DATA.”\n\n\n———. 2007. “The Regularized Iteratively Reweighted MAD Method for Change Detection in Multi- and Hyperspectral Data.” IEEE Transactions on Image Processing 16 (2): 463–78. https://doi.org/10.1109/TIP.2006.888195."
  },
  {
    "objectID": "4_policy_applications.html#sec-summary",
    "href": "4_policy_applications.html#sec-summary",
    "title": "4  Policy Applications",
    "section": "4.1 Summary",
    "text": "4.1 Summary\n\n4.1.1 London\nAs the Capital and most populous city in the UK, London covers a vast area of more than 1,500 square kilometres, with a diverse population of over 8.5 million (Office of National Statistics (n.d.)) and a varying landscape of high density urban area (mainly in the centre) juxtaposed with a large amount of land cover being green or blue (Greater London Authority (2025)). The majority of which sit in the outer London boroughs but there various public green spaces throughout all of London. London was also declared the world’s first National Park City in 2019 with over 50% of the city to be green by 2050 (Greater London Authority (2025)). The administration of London is split into 32 London Boroughs each with their own unique geographies, social demographics and autonomy.\n\n\n4.1.2 London Plan\nThe London Plan os the strategic development strategy for the city. It’s current iteration was by by the Greater London Authority in 2021 (Greater London Authority (2021)). The London Plan sets out the metropolitan policies from London with the 32 London Boroughs following the policies set out to meet their economic, social and environmental responsibilities. The scope of the London Plan is very broad covering topics of building design, heritage, housing, economy and transport. Reviewing all of these could descend into a dissertation size document so I will focus on a GG3 - Greating a healthly city.\n\n4.1.2.1 GG3 Good Growth - Creating a healthy city\nThere are many ways in which to make improve health within cities however these are made more difficult when balancing against improving the economic and social aspects of a city. Policy GG3 encompasses many different approaches in it’s objectives Table 4.1 but a key aspect of this is reducing health problems caused by inactivity through greater access to public open spaces which specifically related to GG3G but also GG3B.\nGG3F aims to reduce exposure to poor air quality which also links back to the aforementioned goals related to public open spaces but also that of GG3C where a Healthy Streets Approach is a priority. The Healthy Streets Approach was published by Transport for London in 2017 and is a framework for creating healthier streets. Some of the aspects promoting sustainable travel, providing cleaner air, places to rest and a relaxing environment Transport for London (2017). All these aspects play a strong part in meeting the goals of GG3.\n\n\n\n\nTable 4.1: Policy GG3 of the London Plan\n\n\n\n\n\n\n\nTo improve Londoners’ health and reduce health inequalities, those involved in planning and development must:\n\n\n\nA\nensure that the wider determinants of health are addressed in an integrated and co-ordinated way, taking a systematic approach to improving the mental and physical health of all Londoners and reducing health inequalities\n\n\n\n\nB\npromote more active and healthy lives for all Londoners and enable them to make healthy choices\n\n\nC\nuse the Healthy Streets Approach to prioritise health in all planning decisions\n\n\nD\nassess the potential impacts of development proposals and Development Plans on the mental and physical health and wellbeing of communities, in order to mitigate any potential negative impacts, maximise potential positive impacts, and help reduce health inequalities, for example through the use of Health Impact Assessments\n\n\nE\nplan for appropriate health and care infrastructure to address the needs of London’s changing and growing population\n\n\nF\nseek to improve London’s air quality, reduce public exposure to poor air quality and minimise inequalities in levels of exposure to air pollution\n\n\nG\nplan for improved access to and quality of green spaces, the provision of new green infrastructure, and spaces for play, recreation and sports\n\n\nH\nensure that new buildings are well-insulated and sufficiently ventilated to avoid the health problems associated with damp, heat and cold\n\n\nI\nseek to create a healthy food environment, increasing the availability of healthy food and restricting unhealthy options.\n\n\n\n\n\n\n\n\nThe London Plan goes into more specific policies and goals which also relate to building a healthy city. Specifically, Chapter 8 of the London Plan focuses on Green Infrastructure and Natural Environment and Chapter 9 on Sustainable Infrastruture.\n\n\n4.1.2.2 Green Infrastructure and Natural Environment\nPolicy G5 Urban Greening Figure 4.1 states that major development should conform to an Urban Greening Factor (UGF) which is a framework for judging how green a development should be. The scoring criteria provides a weighting on the type and maturity of green land cover with the UGF calculated as follows:\n\n(Factor A x Area) + (Factor B x Area) + (Factor C x Area) etc. divided by Total Site Area.\n\nThis provides a good basis for scoring development greeness however as the recommendations are open to be amended by London Boroughs this may cause discrepancies in their implementation (discussed in Section 4.1.2.4)\n\n\n\nFigure 4.1: Policy G5 Urban Greening of the London Plan\n\n\n\n\n4.1.2.3 Sustainable Infrastructure\nChapter 9 of the London focuses on Sustainable Infrastructure with specific goals relating to Improving Air Quality (SI1) and Managing heat risk (SI4). Both of this goals can be interlinked with that of overaching policy of creating a healthy city and the goals of Green Infrastructure (Section 4.1.2.2). Some of these topics will be discussed in Section 3.2.\n\n\n4.1.2.4 The roles of the London Boroughs\nTalk about the diversity and differences in borough generally but using UGF as an example\nA key part of the London Plan is that the ideas and policies created are to be taken forward and implented by each London Borough. Whilst this does open up to differing interpretations and implementations we must be mindful of the very diverse population and land cover of London.\nTaking the example of green infrastructure Section 4.1.2.2 and particularly the development of the Urban Greening Factor, it is positive that a specific scoring framework is put in place. However the policy remains ambiguous by allowing Boroughs to develop their own UGF. This potentially means that there could be 32 different UGFs being applied across all the London Boroughs. Although potentially confusing, particularly for developers, this is very deliberate due to the diverse and distinct differences between the London Boroughs. Particularly when you consider the socio-demographic differences and the availability of open space between boroughs but also specifically between inner and outer London. It would be very difficult to identify the needs of each Borough whilst generalising to the whole of London. Therefore allowing boroughs to implement their own localised UDF is appropriate."
  },
  {
    "objectID": "4_policy_applications.html#sec-applictions",
    "href": "4_policy_applications.html#sec-applictions",
    "title": "4  Policy Applications",
    "section": "4.2 Applications",
    "text": "4.2 Applications\nThe application criterion will refer to how the remotely sensed data you sourced could be used to assist with contributing to the policy goal. How could the data be applied to solve the policy challenge.\nIn this section we will explore how remotely sensed data could be used to help meet the goals of Figure 4.1. I’ll begin by focusing on the UDF and how this can be effectively monitored. The simplest way that remote sensing can be used to contribute to Figure 4.1 is by identifying current land cover as existing green cover counts towards the UDF scores. By using Earth Observation data this reduces the need for manual surveying and is also something that can be monitored as the development progresses. The temporal comparison of green areas provides key statistics to make sure developers have met their targets and also help report on differences in percentage cover of green infrastructure across London which is fundamental to goals such as those of the National Park City (Greater London Authority (2025)).\nThe large temporal scale of remotely sensed data, particularly with the Landsat series going back to the 1970’s, allows comparison of green spaces in the past to the present day and continuing into the future. This provides\n\nA useful criteria for land cover was identified by Jensen (2015) Used to evaluate current land cover - Jensen 2015\nShow basic images of Coal Drops Yard before and now\nUse to identify areas that require stricter UDF measures due to factors such as pollution and urban heat.\nAlthough not specific to this policy, remote sensing can be used to provide a targeted approach to urban greening programmes. Such as the\n\n\n\n\nCamden and Islington used the ideas in these policies to create the Green Infrastructure for Streets guidance (LB Camden, LB Islington, UDL (2024)) and Highway Greening Accelerator programme (London Borough of Camden (2024)) with the aim to improve microclimate, air quality and reduce flood risk. There are secondary benefits to making grey areas green again from improving biodiversity and street scenes to improved mental health."
  },
  {
    "objectID": "4_policy_applications.html#sec-refection",
    "href": "4_policy_applications.html#sec-refection",
    "title": "4  Policy Applications",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nHaving worked in Local Government for almost 20 years and within the London Borough of Camden for nearly 9 of those I believe I can give a good insight into how remote sensing is and could be used to help meet the policies of the London Plan.\nFirstly how is remote sensing used currently, and the answer is….barely at all!\nCamden were fortunate to become part of the Geospatial commission Earth Observation Pilot which ran between 2023/24 but other than that use of remotely sensed data has been virtually non-existent. This is due to previously scare availability of EO data, cost, lack of appropriate software and technical knowledge. Even some projects from the overarching remit of the GLA are outsourced, such as their analysis of Climate Risk which was completed by Bloomberg Associates (Greater London Authority (2024)) rather than procuring, processing and analysing the data in house.\n\n“The view from above offers repeatable, independent, and cost effective ways for the digital (and smart) era to obtain relevant knowledge for social processes, ecological states, and technological innovations” Wellmann et al. (2020)\n\nPresently the cost of implementing remote sensing techniques into smaller boroughs is seen as outweighing the benefits that this can bring. However as we see from the quote above from Wellmann et al. (2020) remotely sensed data is beginning to move more into mainstream particularly when you look Google Earth Engine which removes much of the overheads of dealing with EO data.\nNow that more readily available, cost effective tools are in place we must now showcase the benefits remote sensing brings at a policy level. The foundations for this were beginning to be put in place by the Geospatial Commission but the very recent news that they have now become part of the Government Digital Service has potentially derailed this. Although it is very early days to say anything concrete on this so I will be following updates closely.\nThis bring the fight back to those within individual authorities so the best way is to bring the technology into focus and specific pilot analysis project can be broached to showcase the benefits of such analysis and at a reasonable cost. I am certainly keen to produce tangible products to present at Camden. I can already start to see how the benefits of temporal analysis at this level can helped to guide and focus projects, particularly in the Green Space and climate change spaces where similar analysis can benefit both areas as we have seen with the overlaps in the London Plan policies already discussed.\n\n\n\n\nAlmeida, Cátia Rodrigues de, Ana Cláudia Teodoro, and Artur Gonçalves. 2021. “Study of the Urban Heat Island (UHI) Using Remote Sensing Data/Techniques: A Systematic Review.” Environments 8 (10, 10): 105. https://doi.org/10.3390/environments8100105.\n\n\nGreater London Authority. 2021. “The London Plan 2021 - Table of Contents | London City Hall.” March 1, 2021. https://www.london.gov.uk/programmes-strategies/planning/london-plan/the-london-plan-2021-table-contents.\n\n\n———. 2024. “London Climate Risk Maps.” 2024. https://cityhall.maps.arcgis.com/apps/instant/media/index.html?appid=59236d2e842c4a3ba6480d9dac585d1e.\n\n\n———. 2025. “Parks and Green Spaces | London City Hall.” 2025. https://www.london.gov.uk/programmes-strategies/environment-and-climate-change/parks-green-spaces-and-biodiversity/parks-and-green-spaces.\n\n\nLB Camden, LB Islington, UDL. 2024. “Green Infrastructure for Streets A Paractical Guide to Design, Delivery & Maintenance.” UDL. 2024. https://www.urbandesignlearning.com/resources/publications/details?recordId=recVcJedUUe7jlA6E.\n\n\nLondon Borough of Camden. 2024. “Earth Observation Pilot.” ArcGIS StoryMaps. June 27, 2024. https://storymaps.arcgis.com/stories/2cb162d9c7984d47b5545322ca5b4ea2.\n\n\nOffice of National Statistics. n.d. “Nomis - 2021 Census Area Profile - London Region.” Accessed February 8, 2025. https://www.nomisweb.co.uk/sources/census_2021/report?compare=E12000007.\n\n\nTransport for London. 2017. “Healthy Streets for London.”\n\n\nWellmann, Thilo, Angela Lausch, Erik Andersson, Sonja Knapp, Chiara Cortinovis, Jessica Jache, Sebastian Scheuer, et al. 2020. “Remote Sensing in Urban Planning: Contributions Towards Ecologically Sound Policies?” Landscape and Urban Planning 204 (December): 103921. https://doi.org/10.1016/j.landurbplan.2020.103921."
  },
  {
    "objectID": "1_intro.html#sec-summary",
    "href": "1_intro.html#sec-summary",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nAs a relative newbie to Remote Sensing there was so much new information this week that it’s very difficult to choose even a few things to talk about without writing an whole essay. Therefore I have decided that the best way to summarise this would be through a mind map Figure 1.1.\n\n\n\nFigure 1.1: Introduction to Remote Sensing Mind map\n\n\nThere is so much information that could be discussed here but I’d like to focus on the bands. Images produced at different bands are what makes up the creation of useful and relevant images. Personally I have previously attempted to use earth observation data without understanding the differences between the bands and this made the task at hand incredibly difficult and mainly involved mindlessly following guides and videos just to get a semi-readable output. So this weeks introduction to remote sensing really helped me to understand what bands relate to which information on the ground. And importantly how the different bands can be combined depending on the purpose of any analysis."
  },
  {
    "objectID": "1_intro.html#sec-application",
    "href": "1_intro.html#sec-application",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nThere are numerous applications for remote sensing which have been discussed widely in many articles. Just by searching scholarly articles published in just the past month for the term “remote sensing”, hundreds of articles are returned. By scanning the first few pages articles ranging from fire monitoring, wheat yield prediction, military and flooding are evident. Also, the number of different landscapes that can be monitored are also highly evident, including polar regions, mountains, wetlands, cities, forests and agricultural land.\nWhilst many of the use cases available are fascinating, as this is an introduction to remote sensing it would be easy to get lost in the array of use cases on offer. As such I have instead decided to focuses on a comparison between Landsat-8 and Sentinel-2. There are still a huge amount of articles to consider in this topic, many again with very different use cases however I will consider two more general comparison articles.\n\n1.2.1 Prelimary Sentinel-2 and Landsat 8 Comparison\nDespite the many variables in sensor technology it is possible to compare imagery from Landsat-8 and Sentinel-2 due to an overlap in the bands captured by each. Mandanici and Bitelli (2016) prepared an initial comparison approximately a year after Sentinel-2 was launched in 2015. Landsat-8 was launched in 2013.\nMandanici and Bitelli begin with a basic summary of the sensor which provides useful context for their comparison which summarised in Table 1.1.\n\n\n\n\nTable 1.1: Summary comparison of basic Landsat-8 and Sentinel-2 specifications\n\n\nSatellite\nSpatialResolution\nSwathWidth\nRevisitTime\nSensor\nNumberOfBands\nComparableBands\n\n\n\n\nLandsat-8\n30m\n185km\nOperational Land Imager (OLI)\n16 days\n11\nblue: 485 nm, green: 563 nm, red: 655 nm, NIR: 865 nm, short-wave infrared 1 (SWIR1): 1610 nm, SWIR2: 2200 nm\n\n\nSentinel-2\nup to 10m\n290km\nMultispectral Instruments (MSI)\n5 days\n13\nblue: 490 nm, green: 560 nm, red: 665 nm, NIR: 842 nm, SWIR1: 1910 nm, and SWIR2: 2190 nm\n\n\n\n\n\n\n\n\nSix sites across the Earth were chosen to compare Sentinel/Landsat images, the sites were chosen to provide a mix of land cover types and climatic conditions, the comparison images were taken on the same day to build as close a comparison as possible. Correlation and regression coefficients were then calculated across the bands for the study areas.\nFrom my currently limited remote sensing knowledge I found this methodology difficult to follow due to it’s highly mathematical model, however the overall results showed there was a very good correlation between the corresponding bands. Although limitations were identified including radiometric differences requiring careful evaluation and investigating discrepancies in reflectance values relevance.\n\n\n1.2.2 Comparison using Google Earth Engine\nThe article by Nasiri et al. (2022) was chosen due to it’s more contemporary nature providing a useful and relevant comparison against the preliminary comparison. A further advantage of reviewing this research was it’s methodology of using Google Earth Engine (GEE). We will begin using Google Earth Engine later in the course so it seemed even more appropriate to use this paper.\nThe specific methodology for comparing Landsat-8 and Sentinel-2 involved producing time-series analysis of a single study area (Tehran Province, Iran) using images from both satellites. As the resolutions did not match the MSI data was downsampled to the match that of OLI.\nThe first output was a range of comparison images Figure 1.2 which help demonstrate how difficult it is for the human eye to identify variations in accuracy of this level of data.\n\n\n\nFigure 1.2: Landsat-8 and Sentinel-2 image comparison - using False-colour images (R: NIR, G:red, B: green) across seasons: (a) Spring, (b) Summer and (c) Autumn\n\n\nThe second output was more in-depth evaluation\n\n\n1.2.3 Review\nDespite lacking some knowledge around the specific calculations in the analysis and found these to be two very interesting articles. The comparison between the methodologies is quite clear with Nasiri et al. (2022) being easier to follow mainly due to it’s use of more visual representation of the data.\nThe methodology for Mandanici and Bitelli (2016) appears to be a lot less reproducible as there is less detail in this section, it also does not refer to which languages, applications, etc. that were used. Nasiri on the otherhand was more reproducible due to it’s use of Google Earth Engine which has the added bonus of avoiding local storage issues and providing greater computing power for analysis and processing (Carrasco et al. 2019). This may just be due to the fact that Google Earth Engine wasn’t as widely used or known in 2016 as it is was 2022.\nThe main limitations I see with both articles if that the number of samples used was quite low and therefore it cannot be said with absolute certainty whether the results would be replicated in other areas. Mandanici does look at multiple sites but they are chosen for their differing landscapes and climate. Nasiri on the other hand only uses one sample area but with clearly distinguished land uses, Whilst this is useful as it identified variations in accuracy across land uses (artificial land 95-100%, bare earth 71-86%) it is not clear whether similar results would be expected in other areas of interest."
  },
  {
    "objectID": "1_intro.html#sec-refection",
    "href": "1_intro.html#sec-refection",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nBoth articles discussed in Section 1.2 provide a good overview of both Landsat-8 and Sentinel-2 which helps to consolidate some of the topics taught in class this week. Especially in relation to how different bands can be used for different purposes. This will be extremely useful in the coming months as we look at our own analysis in this course and in CASA0025, but also as part of work as we begin to use a new Earth Observation Data Hub.\nSome of the methodology of both papers is still difficult for me to process, particularly around the specific analysis and calculations, but hopefully this is because it is still the first week of remote sensing. However reading these articles really helped my understanding of the use cases of both satellites and specifically their similiarities and importantly how the spectral resolution of the same bands have slight variations to be aware of. Also understanding how bands, can be combined in different ways and in different applications to produce similar images for analysis. This then helps to provide even more comparable images across a larger temporal scale as any gaps in imagery (possibly due to constraints such as scattering and in particular cloud cover) from one satellite may be able to be filled by the other.\nAnother topic I would have liked to explore is the effect that different types of scattering has on the images captured and how any pre-processing by the agencies responsible for the data affects the images that we see.\n\n\n\n\nCarrasco, Luis, Aneurin W. O’Neil, R. Daniel Morton, and Clare S. Rowland. 2019. “Evaluating Combinations of Temporally Aggregated Sentinel-1, Sentinel-2 and Landsat 8 for Land Cover Mapping with Google Earth Engine.” Remote Sensing 11 (3, 3): 288. https://doi.org/10.3390/rs11030288.\n\n\nMandanici, Emanuele, and Gabriele Bitelli. 2016. “Preliminary Comparison of Sentinel-2 and Landsat 8 Imagery for a Combined Use.” Remote Sensing 8 (12, 12): 1014. https://doi.org/10.3390/rs8121014.\n\n\nNasiri, Vahid, Azade Deljouei, Fardin Moradi, Seyed Mohammad Moein Sadeghi, and Stelian Alexandru Borz. 2022. “Land Use and Land Cover Mapping Using Sentinel-2, Landsat-8 Satellite Images, and Google Earth Engine: A Comparison of Two Composition Methods.” Remote Sensing 14 (9, 9): 1977. https://doi.org/10.3390/rs14091977."
  },
  {
    "objectID": "4_policy_applications.html#sec-intro",
    "href": "4_policy_applications.html#sec-intro",
    "title": "4  Policy Applications",
    "section": "4.1 Introduction",
    "text": "4.1 Introduction\n\n4.1.1 London\nAs the Capital and most populous city in the UK, London covers a vast area of more than 1,500 square kilometres, with a diverse population of over 8.5 million (Office of National Statistics (n.d.)) and a varying landscape of high density urban area (mainly in the centre) juxtaposed with a large amount of land cover being green or blue (Greater London Authority (2025)). The majority of which sit in the outer London boroughs but there various public green spaces throughout all of London. London was also declared the world’s first National Park City in 2019 with over 50% of the city to be green by 2050 (Greater London Authority (2025)). The administration of London is split into 32 London Boroughs each with their own unique geographies, social demographics and autonomy.\n\n\n4.1.2 London Plan\nThe London Plan os the strategic development strategy for the city. It’s current iteration was by by the Greater London Authority in 2021 (Greater London Authority (2021)). The London Plan sets out the metropolitan policies from London with the 32 London Boroughs following the policies set out to meet their economic, social and environmental responsibilities. The scope of the London Plan is very broad covering topics of building design, heritage, housing, economy and transport. Reviewing all of these could descend into a dissertation size document so I will focus on a GG3 - Greating a healthly city.\n\n4.1.2.1 GG3 Good Growth - Creating a healthy city\nThere are many ways in which to make improve health within cities however these are made more difficult when balancing against improving the economic and social aspects of a city. Policy GG3 encompasses many different approaches in it’s objectives Table 4.1 but a key aspect of this is reducing health problems caused by inactivity through greater access to public open spaces which specifically related to GG3G but also GG3B.\nGG3F aims to reduce exposure to poor air quality which also links back to the aforementioned goals related to public open spaces but also that of GG3C where a Healthy Streets Approach is a priority. The Healthy Streets Approach was published by Transport for London in 2017 and is a framework for creating healthier streets. Some of the aspects promoting sustainable travel, providing cleaner air, places to rest and a relaxing environment Transport for London (2017). All these aspects play a strong part in meeting the goals of GG3.\n\n\n\n\nTable 4.1: Policy GG3 of the London Plan\n\n\n\n\n\n\n\nTo improve Londoners’ health and reduce health inequalities, those involved in planning and development must:\n\n\n\nA\nensure that the wider determinants of health are addressed in an integrated and co-ordinated way, taking a systematic approach to improving the mental and physical health of all Londoners and reducing health inequalities\n\n\n\n\nB\npromote more active and healthy lives for all Londoners and enable them to make healthy choices\n\n\nC\nuse the Healthy Streets Approach to prioritise health in all planning decisions\n\n\nD\nassess the potential impacts of development proposals and Development Plans on the mental and physical health and wellbeing of communities, in order to mitigate any potential negative impacts, maximise potential positive impacts, and help reduce health inequalities, for example through the use of Health Impact Assessments\n\n\nE\nplan for appropriate health and care infrastructure to address the needs of London’s changing and growing population\n\n\nF\nseek to improve London’s air quality, reduce public exposure to poor air quality and minimise inequalities in levels of exposure to air pollution\n\n\nG\nplan for improved access to and quality of green spaces, the provision of new green infrastructure, and spaces for play, recreation and sports\n\n\nH\nensure that new buildings are well-insulated and sufficiently ventilated to avoid the health problems associated with damp, heat and cold\n\n\nI\nseek to create a healthy food environment, increasing the availability of healthy food and restricting unhealthy options.\n\n\n\n\n\n\n\n\nThe London Plan goes into more specific policies and goals which also relate to building a healthy city. Specifically, Chapter 8 of the London Plan focuses on Green Infrastructure and Natural Environment and Chapter 9 on Sustainable Infrastruture.\n\n\n4.1.2.2 Green Infrastructure and Natural Environment\nPolicy G5 Urban Greening Figure 4.1 states that major development should conform to an Urban Greening Factor (UGF) which is a framework for judging how green a development should be. The scoring criteria provides a weighting on the type and maturity of green land cover with the UGF calculated as follows:\n\n(Factor A x Area) + (Factor B x Area) + (Factor C x Area) etc. divided by Total Site Area.\n\nThis provides a good basis for scoring development greeness however as the recommendations are open to be amended by London Boroughs this may cause discrepancies in their implementation (discussed in Section 4.1.2.4)\n\n\n\nFigure 4.1: Policy G5 Urban Greening of the London Plan\n\n\n\n\n4.1.2.3 Sustainable Infrastructure\nChapter 9 of the London focuses on Sustainable Infrastructure with specific goals relating to Improving Air Quality (SI1) and Managing heat risk (SI4). Both of this goals can be interlinked with that of overaching policy of creating a healthy city and the goals of Green Infrastructure (Section 4.1.2.2). Some of these topics will be discussed in Section 4.2.\n\n\n4.1.2.4 The roles of the London Boroughs\nTalk about the diversity and differences in borough generally but using UGF as an example\nA key part of the London Plan is that the ideas and policies created are to be taken forward and implented by each London Borough. Whilst this does open up to differing interpretations and implementations we must be mindful of the very diverse population and land cover of London.\nTaking the example of green infrastructure Section 4.1.2.2 and particularly the development of the Urban Greening Factor, it is positive that a specific scoring framework is put in place. However the policy remains ambiguous by allowing Boroughs to develop their own UGF. This potentially means that there could be 32 different UGFs being applied across all the London Boroughs. Although potentially confusing, particularly for developers, this is very deliberate due to the diverse and distinct differences between the London Boroughs. Particularly when you consider the socio-demographic differences and the availability of open space between boroughs but also specifically between inner and outer London. It would be very difficult to identify the needs of each Borough whilst generalising to the whole of London. Therefore allowing boroughs to implement their own localised UDF is appropriate."
  },
  {
    "objectID": "4_policy_applications.html#sec-implementation",
    "href": "4_policy_applications.html#sec-implementation",
    "title": "4  Policy Applications",
    "section": "4.2 Implentation",
    "text": "4.2 Implentation\nPolicy GG3 (Section 4.1.2.1) aims to create a healthy London for all but how can remote sensing help achieve this goal. I will explore how this is possible in the context of the specific policies mentioned in Section 4.1.2.\n\n4.2.1 Policy G5 - Urban Greening Factor\nAs existing green cover counts towards UGF scores, EO data can be used to reduce manual surveying and which can be monitored during development progress. Temporal comparison of green areas ensures developers meet targets and also help report on differences in percentage cover of green infrastructure which is fundamental to goals of the National Park City (Greater London Authority (2025)). High temporal availability of data allows comparison of green spaces in the past, present and future. In the UGF example we can calculate areas of different types of green spaces to be used for the UGF calculation, this could be extended further by using Normalised Difference Vegetation Index (NDVI) to assess the vegetation condition to ensure that green areas remain viable in future.\n\n\n4.2.2 Policy SI1 - Improving Air Quality\nSentinel-5 (S5P) provides data related to pollution-particles, such as NO2, SO2, CO and O3, so can be used to monitor air quality, however with a coarse spatial resolution identifying pollution hot spots may prove difficult without an element of enhancement.\nWith prepared data it’s possible to monitor where pollution is prevalent and which particular particles are causing poor air quality allowing for targeted efforts in these areas. Whether through further monitoring using in-situ air quality monitors or prioritising improvement projects, including dual purpose urban/highway greening projects which meet the priorities of the HSA (Section 4.1.2.1).\n\n\n4.2.3 Policy SI4 - Managing Heat Risk\nLandsat 8/9 provides resampled thermal imagery at 30m spatial resolution (Almeida, Teodoro, and Gonçalves (2021)). This identifies areas at significant heat risk therefore allowing prioritisation of mitigation projects, or to build specific policies in specific areas such as through Neighbourhood Plans.\n\n\n4.2.4 Generalised Application - Highway Greening\nIn 2022/23, Camden and Islington used these policies to create the Green Infrastructure for Streets guidance (LB Camden, LB Islington, UDL (2024)) and Highway Greening Accelerator programme (London Borough of Camden (2024)) with the aim to improve microclimate, air quality and flood risk. Also the secondary benefits of improving biodiversity and street scenes which improve mental health therefore adhering to the HSA framework.\nNDVI images were produced for vegetation identification (Figure 4.2), then combined with datasets like flood risk and public open space to build a weighted risk classification. This was fed into a site suitability analysis tool to build a dataset that is used to identify areas of increased need of urban greening.\n\n\n\nFigure 4.2: Normalised Difference Vegetation Index (NDVI) for an area of Camden around the Hampstead area"
  },
  {
    "objectID": "3_data_corrections.html#sec-3-summary",
    "href": "3_data_corrections.html#sec-3-summary",
    "title": "3  Remote Sensing Data and Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nThis week we delved deeper into remote sensing topics particularly data corrections, joining and enhancements. Lots of new terms were raised and some of the concepts were challenging to understand so it’s easiest to summarise these terms by building a Table 3.1. A lot of these terms could have entire lectures dedicated to them so I attempt to put these into a simple terms as possible.\n\n\n\n\nTable 3.1: Glossary of remote sensing terminology.  Sources: GISGeography (2015). ESRI (2025), USGS (2025), Jaadi (2024), Irons and Petersen (1981), Wen et al. (2024)\n\n\nTerm\nDescription\n\n\n\n\nScan Line Corrector\nDevice that compensates for motion distortions in satellite imagery caused by satellite movement.\n\n\nGeometric Correction\nThe process of correcting spatial distortions in remote sensing imagery to align with map coordinates. This is a similar process to that of paper maps being digitised and corrected to align with digitial representation of the Earth. It involves the use of ground control points identified on the captured image and a \"gold standard\" image, then using transformation algorithms to align the image.\n\n\nAtmospheric Correction\nRemoving the atmospheric effects (e.g., scattering, absorption) from data values to retrieve the surface reflectance. It is always recommended to use atmospheric correction as this removes hazing from images.\n\n\nDark Object Subtraction (DOS)\nA technique for atmospheric correction that finds the values of the darkest values and then subtracts the that from each pixel. The simplest and mot widely used atmospheric correction technique.\n\n\nPseudo-invariant features (PIF)\nFeatures assumed to have stable reflectance over time. Examples include water bodies, rocky surfaces. Can be used for atmospheric correction, sensor callibration and change detection\n\n\nAtmospheric Radiative Transfer Models\nMathematical models used to simulate the interaction of light with the atmosphere. Commercial software available for atmospheric correction includes ACORN (Atmospheirc CORrection Now), FLAASH (Fast Line-of-Sight Atmospheric Analysis of Spectral Hypercubes), QUAC (Quick Atmospheric Correction) and ATCOR (Atmospheric Correction of Reflectance). Free software: SMAC (Simplified Model for Atmospheric Correction and Orfeo Toolb\n\n\nEmpirical Line Correction\nA method of atmospheric correction using ground-truth measurements to directly relate image data to reflectance values.\n\n\nField Spectrometer\nPortable instruments used to measure the spectral reflectance of materials in situ.\n\n\nPath Radiance\nThe portion of radiance reflected by the atmosphere e.g. scattering.\n\n\nAtmospheric attenuation\nThe atmospheric absorption of electromagnetic radiation due to materials in the atmosphere (e.g. water vapour, dust)\n\n\nOrthorectification or Topographic correction\nCorrecting distortions in imagery, making the pixels appear at nadair\n\n\nNadir / off-nadir\nNadir: directly beneath a sensor. Off-nadir: any angle except directly beneath the sensor.\n\n\nSolar Zentih\nThe angle between the sun and the vertical direction at a given location.\n\n\nSolar Azimuth\nThe angle of the sun, measured clockwise from the north. North = 0°, East = 90° at sunrise and 270° at sunset\n\n\nRadiometric Callibration\nThe process of converting the captured Digital Number to a radiance or reflectance values.\n\n\nDigital Number (DN)\nThe raw output value (with no units) recorded by a sensor, with each number indicating a range of colours, e.g. an 8 bit image has value 0 (black) to 255 (white). These represent the radiance or reflectance.\n\n\nRadiance\nRadiation that is leaving the Earth\n\n\nSurface Reflectance\nThe ratio of incoming electromagnetic energy that a surface reflects, corrected to account for atmospheric effects and light source.\n\n\nIrradiance\nRadiation that is reaching the Earth such as from the Sun\n\n\nContrast Enhancement\nTechniques used to improve image visibility by increasing the contrast between features.\n\n\nBand ratioing\nDividing the pixel values of one spectral band by another to highlight specific features (e.g., vegetation indices).\n\n\nFiltering\nThe process of enhancing or suppressing specific spatial frequencies in an image.\n\n\nEdge enhancement\nTechniques to highlight boundaries and transitions in imagery.\n\n\nEmbossing\nAn image processing technique that simulates 3D surface relief.\n\n\nPrincipal Comonent Analysis (PCA)\nA technique to take a large complex dataset and reduce it's dimensionality to provide a simplified dataset whilst maintaining the significant patterns and trends. (Jaadi, 2024)\n\n\nTexture\nThe spatial variation/similarity of visual patterns in pixel values, representing surface roughness or smoothness. (Irons, 1981)\n\n\nImage fusion\nA subset of data fusion that focuses on merging images to improve resoluton. This technique migtigates for the differences in spatial, temporaral and spectral resolutions in data collection between satelittes. So this can be used to combine certain Landsat and Sentinel images into a single working image (Wen, 2024).\n\n\nPan Sharpen\nA technique used to enhance the spatial resolution of multispectral images by combining them with a high resolution panchromatic image.\n\n\nData fusion\nThe process of combining data from multiple sources with the goal of improving accuracy and usefulness.\n\n\n\n\n\n\n\n\nA key point raised throughout the lecture was that regression plays a key part in many of the corrections that we looked into. This links back to (Section 1.2) discussion and the regression based methods used by Mandanici and Bitelli (2016). I initially struggled to fully understand this methodology fully so this lecture helped to consolidate those comparisons by clearly explaining the important role that regression plays in remote sensing.\nOnce again we have near endless options to analyse further but this week I will focus on atmospheric correction by comparing against radiometric normalisation. This specifically looks at the differences and accuracy of relative and absolute correction."
  },
  {
    "objectID": "3_data_corrections.html#sec-3-application",
    "href": "3_data_corrections.html#sec-3-application",
    "title": "3  Remote Sensing Data and Corrections",
    "section": "3.2 Applications - Effectiveness of relative and absolute correction",
    "text": "3.2 Applications - Effectiveness of relative and absolute correction\nThe is an interesting area to investigate is because the availability of the inputs required for absolute atmospheric correction is often generalised over an specified area or season potentially leading to accuracy issues. Both Hu et al. (2011) and Bernardo et al. (2016) investigation the impact of this generalisation, whilst there are differences between the two methodologies which will be discussed later but first lets look at the similarities:\n\ncompares using Landsat imagery\ncompares a single study area using time series images\nuses FLAASH for absolute atmospheric correction\nuses multivariate alternative detection (MAD) for relative radiometric normalisation\n\n\n3.2.1 Absolute Vs Relative methods and results\nBernardo et al. (2016) investigated the reflectance errors comparing by assessing root mean squared error (RMSE) and the mean absolute percent error (MAPE). A comparison was made against the FLAASH (absolute method) against IRMAD - iteratively reweighted multivariate alteration detection (relative method) correction methods. The results in Table 3.2 clearly show greater levels in inaccuracy from the absolute method (FLAASH) in both methods of comparison across nearly all bands.\n\n\n\n\nTable 3.2: Reflectance errors from FLAASH and IRMAD corrections (Bernardo et al. 2016)\n\n\nOLI band\nRMSE (%) FLAASH\nRMSE (%) IRMAD\nMAPE (%) FLAASH\nMAPE (%) IRMAD\n\n\n\n\nCoastal (440nm)\n133.45\n31.22\n131.45\n25.82\n\n\nBlue (480nm)\n53.70\n25.06\n51.73\n21.84\n\n\nGreen (560nm)\n11.50\n12.29\n9.61\n9.46\n\n\nRed (655nm)\n34.45\n20.03\n33.38\n16.98\n\n\nNIR (865nm)\n88.29\n49.97\n81.71\n45.37\n\n\n\n\n\n\n\n\nHu et al. (2011) used MAD, over Bernardo et al. (2016)’s technique of IRMAD, which provides a more basic detection of change as it is a one-pass approach and does not iteratively refine the results, also IRMAD are much less noisy than MAD(Nielsen (2005), Nielsen (2007)). There is also a third approach, regularised IRMAD which can perform even better but this was not part of the studies being compared.\nHu et al. (2011) used regression to assess the difference between corrections and the findings can be reviewed through the standard deviation results of each method. Generally the results are comparable to Bernardo et al. (2016) with both methods reducing radiometric distortion, however relative normalisation corrects it more effectively. This is shown by the lower standard deviations of relative normalisation versus atmospheric correction across all bands (Table 3.3).\n\n\n\n\nTable 3.3: Standard Deviation of the difference in each band for relative normalisation against atmospheric correction\n\n\nBand\nBand 1\nBand 2\nBand 3\nBand 4\nBand 5\nBand 7\n\n\n\n\nSTD of Relative Normalization\n0.0013\n0.0018\n0.0017\n0.0045\n0.0066\n0.0047\n\n\nSTD of Atmospheric Correction\n0.0025\n0.0030\n0.0033\n0.0086\n0.0083\n0.0074\n\n\n\n\n\n\n\n\n\n\n3.2.2 Review\nWhilst the papers talk about absolute corrections having high percentage error in certain bands this could be specific to the location of the study and any assumptions made throughout. There are so many variables that it would be highly improbable to produce a study that could feasibly review all of these aspects. Ideally it would be possible to say exactly what corrections/enhancements to apply to any image to provide the optimal output. However that is just not possible, considering variables including atmospheric conditions, topological factors, sensor differences, then we can begin to see why there is no single set of tools for analysis.\nThis is evident in both papers and also seen in other papers such as Mandanici and Bitelli (2016) and Nasiri et al. (2022). It could appear that the scope is quite limited as they focus on very small samples for their analysis (previously discussed in week 1). However if we consider this from a technical point of view then simply the amount of computational power required to process much larger samples is very restrictive and time-consuming."
  },
  {
    "objectID": "3_data_corrections.html#sec-3-refection",
    "href": "3_data_corrections.html#sec-3-refection",
    "title": "3  Remote Sensing Data and Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nIt was clear early on that the topics discussed this week could have lectures dedicated to them. However as I delved deeper into the concepts I could really start to see the benefit corrections and enhancements have as part of wider studies, as long as the impact of these have on results is considered especially regarding the specific use case that is being analysed.\nI’m interested in putting this into practice through the Earth Observation Data Hub that Camden will soon have access to. I want to explore the different data types and can now understand the differences between products and in particular what information can be derived from available bands. Most importantly I will no longer take results at face value and will use this knowledge to be critical and actually think how results can be improved. This is a vast improvement on previous EO work completed which involved blindly following guides to get results that seems similar.\nOne final note, this week’s lecture and learning diary improved my overall understanding of the challenges with remote sensing data, but I’m glad that the processing is built into existing packages or through Analysis Ready Data.\n\n\n\n\nBernardo, Nariane, Fernanda Watanabe, Thanan Rodrigues, and Enner Alcântara. 2016. “An Investigation into the Effectiveness of Relative and Absolute Atmospheric Correction for Retrieval the TSM Concentration in Inland Waters.” Modeling Earth Systems and Environment 2 (3): 114. https://doi.org/10.1007/s40808-016-0176-9.\n\n\nESRI. 2025. “GIS Dictionary.” 2025. https://support.esri.com/en-us/gis-dictionary.\n\n\nGISGeography. 2015. “What Is Atmospheric Correction in Remote Sensing?” GIS Geography. November 7, 2015. https://gisgeography.com/atmospheric-correction/.\n\n\nHu, Yong, Liangyun Liu, Lingling Liu, and Quanjun Jiao. 2011. “Comparison of Absolute and Relative Radiometric Normalization Use Landsat Time Series Images.” In MIPPR 2011: Remote Sensing Image Processing, Geographic Information Systems, and Other Applications, edited by Faxiong Zhang and Faxiong Zhang, 8006:800616. SPIE / International Society for Optics and Photonics. https://doi.org/10.1117/12.902076.\n\n\nIrons, James R, and Gary W Petersen. 1981. “Texture Transforms of Remote Sensing Data.” Remote Sensing of Environment 11 (January): 359–70. https://doi.org/10.1016/0034-4257(81)90033-X.\n\n\nJaadi. 2024. “Principal Component Analysis (PCA) Explained.” Built In. 2024. https://builtin.com/data-science/step-step-explanation-principal-component-analysis.\n\n\nMandanici, Emanuele, and Gabriele Bitelli. 2016. “Preliminary Comparison of Sentinel-2 and Landsat 8 Imagery for a Combined Use.” Remote Sensing 8 (12, 12): 1014. https://doi.org/10.3390/rs8121014.\n\n\nNasiri, Vahid, Azade Deljouei, Fardin Moradi, Seyed Mohammad Moein Sadeghi, and Stelian Alexandru Borz. 2022. “Land Use and Land Cover Mapping Using Sentinel-2, Landsat-8 Satellite Images, and Google Earth Engine: A Comparison of Two Composition Methods.” Remote Sensing 14 (9, 9): 1977. https://doi.org/10.3390/rs14091977.\n\n\nNielsen, Allan Aasbjerg. 2005. “AN ITERATIVE EXTENSION TO THE MAD TRANSFORMATION FOR CHANGE DETECTION IN MULTI- AND HYPERSPECTRAL REMOTE SENSING DATA.”\n\n\n———. 2007. “The Regularized Iteratively Reweighted MAD Method for Change Detection in Multi- and Hyperspectral Data.” IEEE Transactions on Image Processing 16 (2): 463–78. https://doi.org/10.1109/TIP.2006.888195.\n\n\nUSGS. 2025. “USGS Isis: Glossary.” 2025. https://isis.astrogeology.usgs.gov/8.1.0/documents/Glossary/Glossary.html.\n\n\nWen, Yanfeng, Peng Chen, Zhenhua Zhang, and Yunzhou Li. 2024. “Cross-Attention-Based High Spatial-Temporal Resolution Fusion of Sentinel-2 and Sentinel-3 Data for Ocean Water Quality Assessment.” Remote Sensing 16 (24, 24): 4781. https://doi.org/10.3390/rs16244781."
  },
  {
    "objectID": "4_policy_applications.html#sec-4-intro",
    "href": "4_policy_applications.html#sec-4-intro",
    "title": "4  Policy Applications",
    "section": "4.1 Introduction",
    "text": "4.1 Introduction\n\n4.1.1 London\n\nCapital and most populous city in the UK\nCovers area of over 1,500 square kilometres\nDiverse population of over 8.5 million (Office of National Statistics (2021))\nVarying land cover of high density urban juxtaposed with large amount being green areas (Greater London Authority (2025)).\nWorld’s first National Park City - 50% green land cover by 2050 (Greater London Authority (2025)).\nAdministration split into 32 boroughs with unique geographies, social demographics and autonomy.\n\n\n\n4.1.2 London Plan\nLondon Plan is the strategic development strategy for the city. It sets out the metropolitan policies with the administrative boroughs following policies to meet economic, social and environmental responsibilities. The scope is very broad, covering topics of building design, heritage, housing, economy and transport.\n\n4.1.2.1 GG3 Good Growth - Creating a healthy city\nPolicy GG3 encompasses different approaches in it’s objectives Table 4.1 with a key aspect being reduction of health problems caused by inactivity through greater access to open spaces which specifically relate to GG3G and GG3B.\nGG3F aims to reduce exposure to poor air quality which links to the goals of public open spaces but also of GG3C where a Healthy Streets Approach (HSA) is a priority. The HSA sets a framework for sustainable travel, cleaner air, places to rest and relaxing environments (Transport for London 2017).\n\n\n\n\nTable 4.1: Policy GG3 of the London Plan\n\n\n\n\n\n\n\nTo improve Londoners’ health and reduce health inequalities, those involved in planning and development must:\n\n\n\nA\nensure that the wider determinants of health are addressed in an integrated and co-ordinated way, taking a systematic approach to improving the mental and physical health of all Londoners and reducing health inequalities\n\n\n\n\nB\npromote more active and healthy lives for all Londoners and enable them to make healthy choices\n\n\nC\nuse the Healthy Streets Approach to prioritise health in all planning decisions\n\n\nD\nassess the potential impacts of development proposals and Development Plans on the mental and physical health and wellbeing of communities, in order to mitigate any potential negative impacts, maximise potential positive impacts, and help reduce health inequalities, for example through the use of Health Impact Assessments\n\n\nE\nplan for appropriate health and care infrastructure to address the needs of London’s changing and growing population\n\n\nF\nseek to improve London’s air quality, reduce public exposure to poor air quality and minimise inequalities in levels of exposure to air pollution\n\n\nG\nplan for improved access to and quality of green spaces, the provision of new green infrastructure, and spaces for play, recreation and sports\n\n\nH\nensure that new buildings are well-insulated and sufficiently ventilated to avoid the health problems associated with damp, heat and cold\n\n\nI\nseek to create a healthy food environment, increasing the availability of healthy food and restricting unhealthy options.\n\n\n\n\n\n\n\n\nChapter 8 focuses on Green Infrastructure and Natural Environment and Chapter 9 on Sustainable Infrastructure, both are key to creating healthy cities.\n\n\n4.1.2.2 Green Infrastructure and Natural Environment\nPolicy G5 Urban Greening (Figure 4.1) states that major development should conform to an Urban Greening Factor (UGF) which is a framework for judging how green a development should be. The scoring criteria provides a weighting on the type and maturity of green land cover.\n\n\n\n\n\n\n\nFigure 4.1: Policy G5 Urban Greening of the London Plan\n\n\n\n\n4.1.2.3 Sustainable Infrastructure\nChapter 9 focuses on Sustainable Infrastructure with goals relating to Improving Air Quality (SI1) and Managing heat risk (SI4). These interlink with the overaching policy of GG3 and the goals of Green Infrastructure (Section 4.1.2.2).\n\n\n4.1.2.4 The roles of the London Boroughs\nLondon Plan implementation is the responsibility of boroughs, whilst possibly equating to differing interpretations we must be aware of the diverse population and land cover of London.\nUsing the development of the UGF (Section 4.1.2.2) as an example. The framework remains ambiguous by allowing boroughs to develop their own UGF. Meaning there could be 32 different UGFs being applied. Although confusing, this is deliberate due to the diverse and distinct differences between boroughs. Considering the socio-demographic differences and the green space availability between boroughs (Greater London Authority (2024b)) and specifically between inner/outer London - it would be very difficult to identify the needs of each borough whilst generalising to all of London. Therefore allowing boroughs to implement their own localised UDF is appropriate."
  },
  {
    "objectID": "4_policy_applications.html#sec-4-reflection",
    "href": "4_policy_applications.html#sec-4-reflection",
    "title": "4  Policy Applications",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nWith 20 years Local Government experience, with 9 of those within Camden I believe I have a unique insight into how remote sensing is/could be used to meet the London Plan policies.\nFirstly how is remote sensing used currently? The short answer is….barely at all!\nEven some projects overseen by GLA such as their Climate Risk analysis are outsourced to companies like Bloomberg Associates (Greater London Authority (2024a)) rather than procuring, processing and analysing the data in house.\n\n“The view from above offers repeatable, independent, and cost effective ways for the digital (and smart) era to obtain relevant knowledge for social processes, ecological states, and technological innovations — Wellmann et al. (2020)\n\nThe cost of implementing remote sensing techniques into smaller boroughs is seen as outweighing the benefits. However as the quote from Wellmann et al. (2020) alludes to remotely sensed data is beginning to move more mainstream particularly with Google Earth Engine which removes much of the associated overheads.\nNow that more readily available, cost effective tools are in place we must use this to showcase the benefits remote sensing brings at a policy level. By building specific pilot analysis projects like Section 4.2.4 the benefits of such analysis can be brought to decision makers attention. I would be keen to take this further to build a tangible, reproducible product that could monitor Tree Canopy cover, as this has often been requested but without the resource or skills to implement. This is just one aspect can help achieve the London Plan goals that have already been discussed.\n\n\n\n\nAlmeida, Cátia Rodrigues de, Ana Cláudia Teodoro, and Artur Gonçalves. 2021. “Study of the Urban Heat Island (UHI) Using Remote Sensing Data/Techniques: A Systematic Review.” Environments 8 (10, 10): 105. https://doi.org/10.3390/environments8100105.\n\n\nGreater London Authority. 2024a. “Air Quality Monitoring - Diffusion Tube Results - London Datastore.” https://data.london.gov.uk/dataset/air-quality-monitoring-diffusion-tube-results.\n\n\n———. 2024b. “Green Cover Map.” GLA Intelligence; Analysis Unit. 2024. https://apps.london.gov.uk/green-cover.\n\n\n———. 2025. “Parks and Green Spaces | London City Hall.” 2025. https://www.london.gov.uk/programmes-strategies/environment-and-climate-change/parks-green-spaces-and-biodiversity/parks-and-green-spaces.\n\n\nLB Camden, LB Islington, UDL. 2024. “Green Infrastructure for Streets A Paractical Guide to Design, Delivery & Maintenance.” UDL. 2024. https://www.urbandesignlearning.com/resources/publications/details?recordId=recVcJedUUe7jlA6E.\n\n\nLondon Borough of Camden. 2024. “Earth Observation Pilot.” ArcGIS StoryMaps. June 27, 2024. https://storymaps.arcgis.com/stories/2cb162d9c7984d47b5545322ca5b4ea2.\n\n\nOffice of National Statistics. 2021. “Nomis - 2021 Census Area Profile - London Region.” 2021. https://www.nomisweb.co.uk/sources/census_2021/report?compare=E12000007.\n\n\nTransport for London. 2017. “Healthy Streets for London.”\n\n\nWellmann, Thilo, Angela Lausch, Erik Andersson, Sonja Knapp, Chiara Cortinovis, Jessica Jache, Sebastian Scheuer, et al. 2020. “Remote Sensing in Urban Planning: Contributions Towards Ecologically Sound Policies?” Landscape and Urban Planning 204 (December): 103921. https://doi.org/10.1016/j.landurbplan.2020.103921."
  },
  {
    "objectID": "1_intro.html#sec-1-summary",
    "href": "1_intro.html#sec-1-summary",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nAs a relative newbie to remote sensing there was so much new information this week that it’s very difficult to choose even a few things to talk about without writing an whole essay. Therefore I have decided that the best way to summarise this would be through a mind map Figure 1.1.\n\n\n\n\n\n\n\nFigure 1.1: Introduction to remote sensing mind-map\n\n\nThere is so many topics that could be discussed further but to focus quickly on the spectral bands. Images produced at different bands are what make up the creation of useful and relevant images. Personally I have previously attempted to use earth observation data without understanding the differences between the bands and this made the task at hand incredibly difficult and mainly involved mindlessly following guides and videos just to get a semi-readable output. So this weeks introduction to remote sensing really helped me to understand what bands relate to which information on the ground. And importantly how the different bands can be combined depending on the purpose of any analysis. The list of use cases from combining spectral bands is incredible, EOS Data Analytics (2025) and USGS (2024) provide a succinct summary of some of the common use cases.\nWhilst many of the use cases available are fascinating, as this is an introduction to remote sensing it would be easy to get lost in the amount of use cases on offer. As such I have instead decided to focus on a comparison between two of the more openly available satellites, Landsat-8 and Sentinel-2."
  },
  {
    "objectID": "1_intro.html#sec-1-application",
    "href": "1_intro.html#sec-1-application",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nUsing the basic summary (Table 1.1) we can quickly see key differences between Landsat-8 (LS8) and Sentinel-2 (S2) particularly the spatial resolution and number of bands. However there are six comparable bands which means we can use the data of each satellite to compare against each other. This has the bonus of greater temporal availability. Although we should be wary of subtle differences between wavelengths when making comparisons. The differences in spatial resolution should also be considered and may require resampling dependent on use case.\n\n\n\n\nTable 1.1: Summary comparison of basic Landsat-8 and Sentinel-2 specifications Mandanici and Bitelli (2016)\n\n\nSatellite\nSpatialResolution\nSwathWidth\nSensor\nRevisitTime\nNumberOfBands\nComparableBands\n\n\n\n\nLandsat-8\n30m\n185km\nOperational Land Imager (OLI)\n16 days\n11\nblue: 485 nm, green: 563 nm, red: 655 nm, NIR: 865 nm, short-wave infrared 1 (SWIR1): 1610 nm, SWIR2: 2200 nm\n\n\nSentinel-2\nup to 10m\n290km\nMultispectral Instruments (MSI)\n5 days\n13\nblue: 490 nm, green: 560 nm, red: 665 nm, NIR: 842 nm, SWIR1: 1910 nm, and SWIR2: 2190 nm\n\n\n\n\n\n\n\n\nVarious methodologies can be employed to compare LS8 and S2, Mandanici and Bitelli (2016) uses regression/correlation methods whereas Nasiri et al. (2022) complements this using visual comparisons. Both options are effective but the visual elements would be simpler to understand if used for policy makers rather than sensor comparison.\nThe statistical approach (Mandanici and Bitelli 2016) showed a positive correlation between the corresponding bands. Although limitations identified included radiometric differences and discrepancies in reflectance value’s relevance. The radiometric differences are identified as ~2.5% for all common bands (Barsi et al. (2018)), the significance of which is dependent on use-case. The importance of statistical methods is highlighted by visualising differences between LS8 and S2 Figure 1.2. The S2 image is slightly darker but it is difficult to spot any key differences. Therefore at this level of analysis it could be suitable to use either sensor’s data.\n\n\n\nFigure 1.2: Landsat-8 and Sentinel-2 image comparison - using False-colour images (R: NIR, G:red, B: green) across seasons: (a) Spring, (b) Summer and (c) Autumn. Nasiri et al. (2022)\n\n\nFor more nuanced analysis the sensor’s differences begin to have greater influence. Particularly evident in Figure 1.3 where artificial land identified by LS8 (DS4) within the water body is far greater than the S2 image (D2). This emphasises the significance of different use cases that comparable datasets are used.\n\n\n\nFigure 1.3: Comparison between the classification results of different parts of the study area. (D-1) S-2 seasonal composites, (D-2) S-2 percentile metrics, (D-3) L-8 seasonal composites, and (D-4) L-8 percentile metrics.\n\n\n\n1.2.1 Limitations\nThe work of Mandanici and Bitelli (2016) appears less reproducible as there is less transparency about the tools used. This is likely due to the need for propitiatory applications to produce the analysis. This is also a comparison paper so the specific methodology and tools used may be seen as insignificant compared to the results. Nasiri et al. (2022) are more transparent about their use of Google Earth Engine (GEE). GEE avoids local storage issues and provides greater computing power for analysis and processing (Carrasco et al. 2019) making it accessible at a lower cost.\nA general issue of remote sensing papers is the small samples used. Therefore it cannot be said with certainty whether results would be replicated in other areas. Mandanici and Bitelli (2016) choose sites of differing landscapes and climate, Nasiri et al. (2022) used a single area with distinguishable land uses. Whilst useful it’s not clear whether similar results are expected in other areas of interest. Although computational resource and time would restrict larger area analysis."
  },
  {
    "objectID": "1_intro.html#sec-1-refection",
    "href": "1_intro.html#sec-1-refection",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nBoth articles discussed in Section 1.2 provide a good overview of both Landsat-8 and Sentinel-2 which helps to consolidate some of the topics taught in class this week. Especially in relation to how different bands can be used for different purposes. This will be extremely useful in the coming months as we look at our own analysis in this course and in CASA0025, but also as part of work as we begin to use a new Earth Observation Data Hub.\nSome of the methodology of both papers is still difficult for me to process, particularly around the specific analysis and calculations, but hopefully this is because it is still the first week of remote sensing. However reading these articles really helped my understanding of the use cases of both satellites and specifically their similiarities and importantly how the spectral resolution of the same bands have slight variations to be aware of. Also understanding how bands, can be combined in different ways and in different applications to produce similar images for analysis. This then helps to provide even more comparable images across a larger temporal scale as any gaps in imagery (possibly due to constraints such as scattering and in particular cloud cover) from one satellite may be able to be filled by the other.\nAnother topic I would have liked to explore is the effect that different types of scattering has on the images captured and how any pre-processing by the agencies responsible for the data affects the images that we see.\n\n\n\n\nCarrasco, Luis, Aneurin W. O’Neil, R. Daniel Morton, and Clare S. Rowland. 2019. “Evaluating Combinations of Temporally Aggregated Sentinel-1, Sentinel-2 and Landsat 8 for Land Cover Mapping with Google Earth Engine.” Remote Sensing 11 (3, 3): 288. https://doi.org/10.3390/rs11030288.\n\n\nMandanici, Emanuele, and Gabriele Bitelli. 2016. “Preliminary Comparison of Sentinel-2 and Landsat 8 Imagery for a Combined Use.” Remote Sensing 8 (12, 12): 1014. https://doi.org/10.3390/rs8121014.\n\n\nNasiri, Vahid, Azade Deljouei, Fardin Moradi, Seyed Mohammad Moein Sadeghi, and Stelian Alexandru Borz. 2022. “Land Use and Land Cover Mapping Using Sentinel-2, Landsat-8 Satellite Images, and Google Earth Engine: A Comparison of Two Composition Methods.” Remote Sensing 14 (9, 9): 1977. https://doi.org/10.3390/rs14091977."
  },
  {
    "objectID": "1_intro.html#sec-1-reflection",
    "href": "1_intro.html#sec-1-reflection",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nThis week brought a range of new topics that we could barely scratch the surface of, however this diary entry and reading the articles discussed in Section 1.2 has really helped to shape my understanding in these areas. Before this I was very much focused on the highest spatial resolution must always be the best but it obviously isn’t that clear cut. The specific use case must be considered to ensure that the correct balance of resolution (all types), spectral bands and costs is made for the expected output.\nA key part of this is how the different spectral bands (and their wavelengths) can be used for different purposes. This will be extremely useful in the coming months as we look at our own analysis in this course and in CASA0025, but also as part of my work in Local Government as we begin to use a new Earth Observation Data Hub. So I’m looking forward to finding out more about the tools at our disposal and how identifying the right sensor’s data can dictate the success of our work.\n\n\n\n\nBarsi, Julia A., Bahjat Alhammoud, Jeffrey Czapla-Myers, Ferran Gascon, Md. Obaidul Haque, Morakot Kaewmanee, Larry Leigh, and Brian L. Markham. 2018. “Sentinel-2A MSI and Landsat-8 OLI Radiometric Cross Comparison over Desert Sites.” European Journal of Remote Sensing 51 (1): 822–37. https://doi.org/10.1080/22797254.2018.1507613.\n\n\nCarrasco, Luis, Aneurin W. O’Neil, R. Daniel Morton, and Clare S. Rowland. 2019. “Evaluating Combinations of Temporally Aggregated Sentinel-1, Sentinel-2 and Landsat 8 for Land Cover Mapping with Google Earth Engine.” Remote Sensing 11 (3, 3): 288. https://doi.org/10.3390/rs11030288.\n\n\nEOS Data Analytics. 2025. “Satellite Band Combinations: Analytical Methods For Imagery.” 2025. https://eos.com/make-an-analysis/.\n\n\nMandanici, Emanuele, and Gabriele Bitelli. 2016. “Preliminary Comparison of Sentinel-2 and Landsat 8 Imagery for a Combined Use.” Remote Sensing 8 (12, 12): 1014. https://doi.org/10.3390/rs8121014.\n\n\nNasiri, Vahid, Azade Deljouei, Fardin Moradi, Seyed Mohammad Moein Sadeghi, and Stelian Alexandru Borz. 2022. “Land Use and Land Cover Mapping Using Sentinel-2, Landsat-8 Satellite Images, and Google Earth Engine: A Comparison of Two Composition Methods.” Remote Sensing 14 (9, 9): 1977. https://doi.org/10.3390/rs14091977.\n\n\nUSGS. 2024. “What Are the Best Landsat Spectral Bands for Use in My Research? | U.S. Geological Survey.” March 19, 2024. https://www.usgs.gov/faqs/what-are-best-landsat-spectral-bands-use-my-research."
  },
  {
    "objectID": "5_google_earth_engine.html#sec-5-intro",
    "href": "5_google_earth_engine.html#sec-5-intro",
    "title": "5  Introduction to Google Earth Engine",
    "section": "5.1 Introduction",
    "text": "5.1 Introduction\n“Google Earth Engine is a cloud-based platform that makes it easy to access high-performance computing resources for processing very large geospatial datasets, without having to suffer the IT pains currently surrounding either. Additionally, and unlike most supercomputing centers, Earth Engine is also designed to help researchers easily disseminate their results to other researchers, policy makers, NGOs, field workers, and even the general public. Once an algorithm has been developed on Earth Engine, users can produce systematic data products or deploy interactive applications backed by Earth Engine’s resources, without needing to be an expert in application development, web programming or HTML.”\n“according to Hansen et al. [8], it only took 100 h to process 654 178 Landsat-7 images (about 707 terabytes) within GEE and produce a global map of forests. This was reported as a great achievement because if they did not use GEE, this process would have taken a million hours to complete.” Amani et al. (2020)\n“In the Google data center, CPUs are abundant. In this environment raw efficiency, while still important, is not as important as the ability to efficiently distribute complex computations across many machines and much of Earth Engine’s performance is due to its ability to marshal and manage a large number of CPUs on a user’s behalf. There is a hard ultimate upper limit on the efficiencies that can be achieved through code or query optimization, but there are fewer limitations on the additional computing resources that can be brought to bear.” Gorelick et al. (2017)\n“One of the benefits of using Earth Engine is that the user is almost completely shielded from the details of working in a parallel processing environment. The system handles and hides nearly every aspect of how a computation is managed, including resource allocation, parallelism, data distribution, and retries. These decisions are purely administrative, and none of them can affect the result of a query, only the speed at which it is produced. The price of liberation from these details is that the user is unable to influence them: the system is entirely responsible for deciding how to run a computation. This results in some interesting challenges in both the design and use of the system.” Gorelick et al. (2017)\n“Batch jobs are each run independently making it much harder for them to negatively impact each other, but to prevent monopolization, jobs are still managed using a shared queuing system, and under heavy load, jobs may wait in the queue until resources become available.”\n“it is not possible to mix Earth Engine library calls with standard local processing idioms. This includes some basic language features like conditionals and loops that depend on computed values, as well as standard numerical packages. Users can still use these external tools, but they cannot apply them directly to Earth Engine proxy objects, sometimes leading to confusion.”"
  },
  {
    "objectID": "5_google_earth_engine.html#sec-5-application",
    "href": "5_google_earth_engine.html#sec-5-application",
    "title": "5  Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\nOne critique that could be aimed at GEE apps is that they do not always analyse the use case they demonstrate. However considering the openness and availability of GEE it cannot be considered as just an academic tool but also an operational one (Kumar and Mutanga (2018)). In fact it provides a very simple way to quickly build an application to raise awareness/profile of a global issue whilst providing the tools for further research into the cause at a local level.\nIn a key example of a GEE application, Global Forest Change (Figure 5.2) we clearly see the forest loss across the globe. However the app itself despite showing a few case study example locations does not identify any deeper cause of forest change. The associated article (Hansen et al. (2013)) however does provide some possible causes, again in a subset of locations. When considering the global extents and the sheer number of factors including local policies that affect localised forest change this is not necessarily surprising. For academics or researchers this provides the background and visualisations to highlight specific areas of concerns and to focus deeper research and analysis in these areas. Whilst for a non-academic audience it provides the tools to focus resources in the right locations without needing to research and develop the potentially costly tools themselves. This is evident in areas like the Amazon rainforest where Hansen et al’s work has been used to fight illegal deforestation (Gonzales (2019)).\n\n\n\n\n\n\nFigure 5.2: Global Forest Change Viewer. Source: Global Land Discovery and Analysis (n.d.)\n\n\nClearly GEE is useful for analysis that occurs over time but what where near real-time information is required such as in disaster management. The user is constrained to the revisit time of the data supplied by GEE, such as Landsat ~16 days or Sentinel-2 ~5 days. Whilst it is still key to analyse pre and post-disaster imagery such as available through HazMapper (Scheip and Wegmann (2021)) it does not provide the real-time data that can make the difference in effective disaster management. In such instances use of commercially available SAR data (to prevent cloud cover issues) with a lower revisit time could be preferred. The issue with this is the response is often proportional to the available resources for that area, so less affluent and lower profile areas may not have resources to provide access this data (Scheip and Wegmann (2021)), therefore tools such as HazMapper may be the only way to aid management of the disaster so are priceless in these instances."
  },
  {
    "objectID": "5_google_earth_engine.html#sec-5-reflection",
    "href": "5_google_earth_engine.html#sec-5-reflection",
    "title": "5  Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nGEE is undoubtedly an exceptional tool which is a great enabler for remote sensing analysis but also of data visualisation with the ease at which apps can be built and published. I’m really looking forward to delving deeper into GEE functionality over the coming weeks and in particularly building applications. Taking this further I’d like to harness the computational power of GEE to identify tree cover and vegetation health in London and the affects this has on air quality. Also to use this to as the basis to explore what measures are effective in improving air quality. This would also help to investigate how useful GEE is “out the box” to deal with issues at a more localised level. In Figure 5.1 we saw some limitations including only allowing 250gb of user data so if we wanted to use very hi-res commercial satellite data within GEE then this will cause issues especially if wanted to be produce time series analysis that would be especially useful in the use case mentioned.\n\n\n\n\nAmani, Meisam, Arsalan Ghorbanian, Seyed Ali Ahmadi, Mohammad Kakooei, Armin Moghimi, S. Mohammad Mirmazloumi, Sayyed Hamed Alizadeh Moghaddam, et al. 2020. “Google Earth Engine Cloud Computing Platform for Remote Sensing Big Data Applications: A Comprehensive Review.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 13: 5326–50. https://doi.org/10.1109/JSTARS.2020.3021052.\n\n\nGlobal Land Discovery and Analysis. n.d. “Global Forest Change.” Accessed March 2, 2025. https://glad.earthengine.app/view/global-forest-change#bl=off;old=off;dl=1;lon=20;lat=10;zoom=3;\n\n\nGonzales, Jenny. 2019. “How a Sheriff in Brazil Is Using Satellites to Stop Deforestation.” Mongabay Environmental News. April 12, 2019. https://news.mongabay.com/2019/04/how-a-sheriff-in-brazil-is-using-satellites-to-stop-deforestation/.\n\n\nGoogle. 2024. “About Google Earth Engine.” Google for Developers. 2024. https://developers.google.com/earth-engine/guides.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. 2017. “Google Earth Engine: Planetary-scale Geospatial Analysis for Everyone.” Remote Sensing of Environment, Big Remotely Sensed Data: Tools, applications and experiences, 202 (December): 18–27. https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A. Tyukavina, D. Thau, et al. 2013. “High-Resolution Global Maps of 21st-Century Forest Cover Change.” Science 342 (6160): 850–53. https://doi.org/10.1126/science.1244693.\n\n\nKumar, Lalit, and Onisimo Mutanga. 2018. “Google Earth Engine Applications Since Inception: Usage, Trends, and Potential.” Remote Sensing 10 (10, 10): 1509. https://doi.org/10.3390/rs10101509.\n\n\nScheip, Corey M., and Karl W. Wegmann. 2021. “HazMapper: A Global Open-Source Natural Hazard Mapping Application in Google Earth Engine.” Natural Hazards and Earth System Sciences 21 (5): 1495–1511. https://doi.org/10.5194/nhess-21-1495-2021."
  },
  {
    "objectID": "5_google_earth_engine.html#sec-5-summary",
    "href": "5_google_earth_engine.html#sec-5-summary",
    "title": "5  Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nGoogle Earth Engine (GEE) is a cloud product specifically for geospatial analysis. It combines a huge catalogue of satellite and geospatial data with a platform for simplified analysis with the benefit of using Google computational power for data processing at large scale (Google (2024)). A key part of GEE is that it is designed to make sharing of results and reproducibility easy for researchers with only limited technical expertise (Gorelick et al. (2017)). GEE provides both a code engine environment and a Python based API that enables automation of process.\nWe will briefly look at a few of the main advantages/limitations of GEE in this section but the full range of benefits are too numerous to cover here so are summarised in Figure 5.1 along with some of the limitations.\n\n\n\nFigure 5.1: Google Earth Engine main advantages and limitatations of big-geo data processing. Amani et al. (2020)\n\n\n\n5.1.1 Terminology\nAt a very basic level there are some terminology and functions that differ to that which we are used to in other remote sensing applications (Table 5.1). However this is a relatively minor issue although it could still cause initial confusion and put users off persevering with GEE despite the huge benefits it can bring. Thankfully there is very comprehensive user guides and tutorials available from Google. Also due to the popularity of GEE there is huge amount user-derived content available.\n\n\n\n\nTable 5.1: Comparison of Remote Sensing and GEE Terminology\n\n\nRemote Sensing Term/function\nGEE Equivalent\n\n\n\n\nRaster\nImage\n\n\nImage Stack\nImageCollection\n\n\nVector\nFeature\n\n\nVector data\nFeatureCollection\n\n\nJoin\n.distFilter, .spatialFilter\n\n\n\n\n\n\n\n\n\n\n5.1.2 Server side processing\nRather than running locally, GEE uses server-side processing to leverage Google’s cloud computing power. This reduces hardware limitations and allows for scalability, often using parallel processing. However, this passes management of the execution process to Google, meaning users have limited visibility and control over optimisation. Whilst this is not an issue for most users, expert researchers who require full control over computational workflows may find this restrictive.\n\n\n5.1.3 Processing Speed\nSpecifically looking at time savings that can be made by harnessing the computational power of GEE. Hansen et al. (2013) states that it took 100 hours to process ~707 terrabytes of Landsat images for global forest change detection in GEE. Without cloud-based processing it would have taken a million hours (Amani et al. (2020)). That does not even account for the process of retrieval, preparation and storage of those images. For many organisations this wouldn’t even be feasible to process without GEE’s cloud infrastructure."
  },
  {
    "objectID": "6_classification.html#sec-6-summary",
    "href": "6_classification.html#sec-6-summary",
    "title": "6  Classification",
    "section": "6.1 Summary",
    "text": "6.1 Summary"
  },
  {
    "objectID": "6_classification.html#sec-6-application",
    "href": "6_classification.html#sec-6-application",
    "title": "6  Classification",
    "section": "6.2 Application",
    "text": "6.2 Application"
  },
  {
    "objectID": "6_classification.html#sec-6-reflection",
    "href": "6_classification.html#sec-6-reflection",
    "title": "6  Classification",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection"
  },
  {
    "objectID": "6_classification_I.html#sec-6-summary",
    "href": "6_classification_I.html#sec-6-summary",
    "title": "6  Classification I",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nThis week we looked at how classification can help build important use cases for remote sensing. Starting with some practical use cases and then onto the theory and methods to produce outputs before practically applying this using Google Earth Engine. A recent example of remote sensing classification was that of the French authorities which identified undeclared private swimming pools and reclaimed €10m in revenue that otherwise wouldn’t have been possible (BBC (2022)). The driver for this was in response to major drought, other use cases include illegal logging (Gonzales (2019)) and forest fires (Hansen et al. (2013)).\n\n6.1.1 Classification\nTraditionally there were two main forms of classification, according to Abburu and Babu Golla (2015) these can be defined as:\n\nSupervised: requires human input to build a training set with the accuracy highly dependent on the samples used for training . Techniques used include Support Vector Machine (SVM) and Random Forest.\nUnsupervised: uses clustering methods to group pixels into clusters then an analyst assigns labels to the clusters. Most commonly used techniques are ISODATA and K-means clustering.\n\nI had planned to conduct a comparison between supervised and unsupervised classification but GISGeography (2016) have already produced a very good and clear summary of these methods (Figure 6.1).\n\n\n\nFigure 6.1: Table highlighting the differences between unsupervised and supervised classification. Source: GISGeography (2016)\n\n\nPicking out some key elements of this, the accuracy of supervised classification is usually more accurate due to the human input of the classification, however this presumes a level of knowledge of the study area in question which may not always be possible.\n\n6.1.1.1 Object Based Image Analysis\nThese traditional classification techniques were orginally mainly used for pixel-based classifiction but since the late 1990s object based classification has become increasingly popular through Object Based Image Analysis (OBIA).\nOBIA groups pixels into an object type which are then used as training data for the actual analysis. The basic steps for all these forms of classification are expertly summarised by Figure 6.2 which also shows how OBIA has increased in popularity since 2008.\n\n\n\nFigure 6.2: Image classification infographic depicting the steps of each classification method (supervised, unsupervised and Object Based Image Analysis), the timeline of their inception and the usage of each method between 2006 and 2013. Source: GISGeography (2014)\n\n\nThere is a clear trend of increased OBIA use from 2008 and it’s unfortunate that an updated version of this infographic is not available. However this does illustrate a shift toward OBIA, this is due to higher accuracy results and classifications especially in high-resolution imagery. This approach is more closely aligned to the human visual interpretation of images rather than a pixel based approach and the key to this is segmentation before classification takes place."
  },
  {
    "objectID": "6_classification_I.html#sec-6-application",
    "href": "6_classification_I.html#sec-6-application",
    "title": "6  Classification I",
    "section": "6.2 Application",
    "text": "6.2 Application\nImage classification has a vast array of use cases as mentioned previously, however lets concentrate on to comparison between pixel-based approaches and object-based.\nThe pixel based approaches includes minimum distance and maximum likelihood algorithms whereas the segmentation approach used by OBIA allows for consideration of colour, scale and texture (Amalisana, Rokhmatullah, and Hernina (2017)). Pixel based is often cited as producing a “salt and pepper” output which equates to more noise as individual pixels can be misclassified. Using the segmentation of OBIA this effect is greatly reduced and builds a clearer picture of how an area is built (Figure 6.3). Here we can see how much clearer the classification of the object based approach is and particularly it’s accuracy at identifying the Cisadane river running through the city which is not visible at all in the pixel-based output. Amalisana, Rokhmatullah, and Hernina (2017) state that pixel based classifications calculated that the accuracy of object based classification was 82.15% where as pixel based only 61.481% (see discussion on accuracy assessments in Section 7.2).\n\n\n\nFigure 6.3: Pixel-based versus object-based classification of Bogor City in 2016. Source:\n\n\nFor general land cover we’ve seen a clear example where OBIA out-performs pixel-based however there are other examples where pixel-based may be the preferred option. Picking the study of wetlands and the work of Norris et al. (2024) where they found using Random Forest classifiers on both pixel and object-based approach that pixel-based was more accurate. This could be attribute to a few variables but most likely the small study area and the number of small-sized plants at the study sites. They also state the key importance of selection of input features, as an vegetation based study it is best to use the images at times of year where the vegetation is developed or flowering.\nSo whilst, OBIA appeared to be the obvious choice for classification we must always consider the use case as well as other variables such as image collection dates, spatial resolution and the specific study aims. Overall we must ensure that the use case is clearly defined before finalising methodology or perhaps compare the results ourselves in our research to ensure that the right option guides our decision making."
  },
  {
    "objectID": "6_classification_I.html#sec-6-reflection",
    "href": "6_classification_I.html#sec-6-reflection",
    "title": "6  Classification I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nThe practical session involved producing our first classified output with GEE. This proved troublesome with errors such as the “Collection query aborted after accumulating over 5000 elements”. There are many threads covering this with differing interpretations and I tried many different “solutions”. However after eventually consulting the GEE coding best practice I realised the issue was related to a print statement not the processing and whilst not ideal this didn’t affect the visualisation.\nMoral of the story…..\n\n\n\nFigure 6.4: Debugging meme. Source: Villalba (2023)\n\n\nI lost time troubleshooting the errors but this was a blessing as I dug deeper into the code and thus gained a better understanding. Eventually my first classification visualisation was produced (Figure 6.5) which appears close to real world but some refinement is needed. Notably a large part of the River Thames is classified as high urban, however this should be resolved by improving the training data.\n\n\n\nFigure 6.5: My first classification output in Goggle Earth Engine\n\n\nAs GEE is so quick to train/run I updated the water training polygons and the output was more accurate (Figure 6.6). However, this had the effect of now incorrectly classifying other water bodies. Continual retraining is needed to refine the output - perhaps by separating “standing water” and “flowing water” into individual training datasets. Despite this it really highlighted what a useful tool GEE is.\n\n\n\nFigure 6.6: Retrained output improving the output of the River Thames\n\n\n\n\n\n\nAbburu, Sunitha, and Suresh Babu Golla. 2015. “Satellite Image Classification Methods and Techniques: A Review.” International Journal of Computer Applications 119 (8): 20–25. https://doi.org/10.5120/21088-3779.\n\n\nAmalisana, Birohmatin, Rokhmatullah, and Revi Hernina. 2017. “Land Cover Analysis by Using Pixel-Based and Object-Based Image Classification Method in Bogor.” IOP Conference Series: Earth and Environmental Science 98 (1): 012005. https://doi.org/10.1088/1755-1315/98/1/012005.\n\n\nBBC. 2022. “Undeclared Pools in France Uncovered by AI Technology.” BBC News: Europe, August 29, 2022. https://www.bbc.com/news/world-europe-62717599.\n\n\nGISGeography. 2014. “Image Classification Techniques in Remote Sensing.” GIS Geography. May 2, 2014. https://gisgeography.com/image-classification-techniques-remote-sensing/.\n\n\n———. 2016. “Supervised and Unsupervised Classification in Remote Sensing.” GIS Geography. June 30, 2016. https://gisgeography.com/supervised-unsupervised-classification-arcgis/.\n\n\nGonzales, Jenny. 2019. “How a Sheriff in Brazil Is Using Satellites to Stop Deforestation.” Mongabay Environmental News. April 12, 2019. https://news.mongabay.com/2019/04/how-a-sheriff-in-brazil-is-using-satellites-to-stop-deforestation/.\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A. Tyukavina, D. Thau, et al. 2013. “High-Resolution Global Maps of 21st-Century Forest Cover Change.” Science 342 (6160): 850–53. https://doi.org/10.1126/science.1244693.\n\n\nNorris, Gregory S., Armand LaRocque, Brigitte Leblon, Myriam A. Barbeau, and Alan R. Hanson. 2024. “Comparing Pixel- and Object-Based Approaches for Classifying Multispectral Drone Imagery of a Salt Marsh Restoration and Reference Site.” Remote Sensing 16 (6, 6): 1049. https://doi.org/10.3390/rs16061049.\n\n\nVillalba, Fernando. 2023. “Please Kill RTFM!” Medium. July 6, 2023. https://nandovillalba.medium.com/platform-engineering-please-kill-rtfm-72de6f01075e."
  },
  {
    "objectID": "6_classification_I.html#ensure-that-the-use-case-is-clearly-defined-before-finalising-methodology-or-perhaps-compare-the-results-ourselves-in-our-own-research-to-ensure-that-the-right-option-guides-our-decision-making.",
    "href": "6_classification_I.html#ensure-that-the-use-case-is-clearly-defined-before-finalising-methodology-or-perhaps-compare-the-results-ourselves-in-our-own-research-to-ensure-that-the-right-option-guides-our-decision-making.",
    "title": "6  Classification I",
    "section": "6.3 Ensure that the use case is clearly defined before finalising methodology or perhaps compare the results ourselves in our own research to ensure that the right option guides our decision making.",
    "text": "6.3 Ensure that the use case is clearly defined before finalising methodology or perhaps compare the results ourselves in our own research to ensure that the right option guides our decision making.\nAs discussed above OBIA requires segmentation of the image into objects, similar to how humans visualises the world. The next phase is the actual classification of this objects, where machine learning plays a vital role in reducing the labour resource. These are termed the classification techniques.\nThe techniques used for supervised and unsupervised classification were mentioned in Section 6.1.1, so now to focus on the techniques for OBIA.\n\n6.3.1 Classification and Regression Trees (CART)\nA form of supervised learning that first segments the data into objects and then uses classification trees to assign labels based on spectral, textual and geometric properties.\n\nregression trees"
  },
  {
    "objectID": "7_classification_II.html#sec-7-summary",
    "href": "7_classification_II.html#sec-7-summary",
    "title": "7  Classification II",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nAs we continued exploring classification we this time spoke about the use of pre-classified over self-classified data.\nWith a wealth of preclassified datasets available it would be very easy to pick these up and use these for the basis of any studies being undertaken. However, if we do not consider the processes used, the accuracy of the data (not just taking the stated accuracy as gospel) and the use cases of the product then we open ourselves up to misinterpretation of both the product and of our own research. In the lecture we discussed Dynamic World’s global 10m resolution near real-time land cover dataset which sounds amazing at face value but delving into the methodology there are concerning details such as the use of Top Of Atmosphere (TOA) data for training which means results could be skewed by atmospheric gases. There is also the fact that we do not control the parameters and outputs of the pre-classified data which makes it less than ideal to use. Specifically would [MODIS]{https://modis.gsfc.nasa.gov/data/dataprod/mod12.php} 500m land cover data actually be useful to investigate a specific urban area, or would ESA’s World Cover product be suitable for recent analysis when it only covers 2020 and 2021.\nWe can see that while pre-classified may be a good point of reference it is highly unlikely to be suitable to more specific use cases. This is before we have even considered the accuracy of the products on offer. To effectively use any data including our own self-classified data we must look at its accuracy to ensure it is fit for purpose. This can become quite complex and how is the accuracy of these techniques measured and what could be the specific issues related to these?"
  },
  {
    "objectID": "7_classification_II.html#sec-7-application",
    "href": "7_classification_II.html#sec-7-application",
    "title": "7  Classification II",
    "section": "7.2 Application",
    "text": "7.2 Application\nOften readers will take the output of an analysis such as a map, chart or diagram as the truth just because it has been published, however the accuracy of such work should also be considered even if it is just for the researcher/analyst’s own piece of mind.\nThis is doubly true as it helps prove that the techniques used for analysis are appropriate for the use case. There is no one correct way to approach classification therefore assessing the accuracy must also be considered in our study. In classification we can use accuracy assessment to legitimise our work but must also be careful that limitations also apply in these assessments.\nFoody (2002) states that the confusion matrix is key to much work on accuracy assessment but is often used without questioning it’s suitability. Foody continues that data used for accuracy assessments will never be completely site-specific due to issues related to misrepresentation of the ground both in remote sensing data and through over generalisation of specified classes. This is something that has always concerned me as I am often questioning myself whether my training data is too specific or generalised. This is something that I would consider exploring the effects of to truly consolidate my own interpretation.\nWhilst there is no perfect solution for accuracy assessment Olofsson et al. (2014) suggested some “good practice” in relation to assessing land change. They summarise that without an accuracy assessment it is not possible to communicate map quality in a meaningful way and state the building blocks of producing effective and high scoring accuracy assessment. Of particular interest is the step related to use of reference data and acknowledging the uncertainty of this “gold standard” dataset. This links back to the Dynamic World example in Section 7.1 where TOA data was being used for training data when there are surely better reference datasets available even if they are harder to access or process."
  },
  {
    "objectID": "7_classification_II.html#sec-7-reflection",
    "href": "7_classification_II.html#sec-7-reflection",
    "title": "7  Classification II",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nOnce aspect of classification that I’m aware that I haven’t mentioned is the spatial autocorrelation of our data. We must be conscious of the first law of geography stating “everything is related to everything else, but near things are more related than distant things.” Meaning that if our samples are too close together then accuracy is likely to be high but the result will be poorer when applied across a wider area, so be aware of overfitting a model. This is yet another thing to consider in any accuracy assessment or when interpreting someone else’s work. Don’t just look at accuracy figures also consider the steps taken to get there and consider any limitations in that methodology or the data used.\n\n\n\n\nFoody, Giles M. 2002. “Status of Land Cover Classification Accuracy Assessment.” Remote Sensing of Environment 80 (1): 185–201. https://doi.org/10.1016/S0034-4257(01)00295-4.\n\n\nOlofsson, Pontus, Giles M. Foody, Martin Herold, Stephen V. Stehman, Curtis E. Woodcock, and Michael A. Wulder. 2014. “Good Practices for Estimating Area and Assessing Accuracy of Land Change.” Remote Sensing of Environment 148 (May): 42–57. https://doi.org/10.1016/j.rse.2014.02.015."
  },
  {
    "objectID": "8_temperature_sar.html#sec-8-summary",
    "href": "8_temperature_sar.html#sec-8-summary",
    "title": "8  Synthetic Aperature Radar (SAR)",
    "section": "8.1 Summary",
    "text": "8.1 Summary\nThroughout this module we have mainly focused on optical satellites and so it was important to look at SAR sensors to understand about how they work and what they can be used for more specifically.\n\n8.1.1 SAR versus Optical\nUnlike passive optical sensors that require solar reflectance to capture data, SAR uses active sensors to emit and measure microwave signals directly. Therefore SAR is not dependent on light availability so can collect data constantly, day or night, and in poor atmospheric conditions. This gives SAR a clear advantage over optical imagery as cloud cover and darkness do not affect data acquisition.\n\n\n\nFigure 8.1: Source: ChatGPT\n\n\nHowever, SAR data comes at high costs, larger data volume and greater computational complexity which limits it’s accessibility. Although Sentinel-1 is one such source of freely available SAR data.\n\n\n8.1.2 How SAR works?\n\n8.1.2.1 Amplitude or Back Scatter\nThe key measurement for SAR which refers to the amount of signal that is reflected back to the sensor. Just like optical sensors the signals use different wavelengths for different purposes.\n\n\n\nFigure 8.2: Source: Flores et al. (2019)\n\n\n\n\n8.1.2.2 Bands\nC-band is the most commonly used as this is used by Sentinel-1. This has a shorter wavelength which does not fully penetrate dense vegetation so can provide a picture of tree canopies. Another common band is L-band which has a larger wavelength which penetrates deeper into canopies providing a clearer picture of ground features. Therefore when comparing SAR data we must ensure that we compare against the same bands. If both bands are available for the same time period then both can used to build a more comprehensive view of what is happening above and below the tree canopy.\n\n\n\nFigure 8.3: Source: Flores et al. (2019)\n\n\n\n\n8.1.2.3 Phase\nHow long it takes the signal to return to the sensor and specifically the point in it’s cycle at which the wave returns to the sensor. As this is related to distance traveled it is very good for identifying changes in ground level that would otherwise extremely difficult to monitor.\n\n\n8.1.2.4 Radiometric Terrain Correction\nAs SAR data is capture off-nadir then it is susceptible to shading (areas not illuminated due to the angle of incidence) and foreshortening (features appear brighter as they are closer to the sensor). Therefore a technique called Radiometric Terrain Correction is applied to correct the images. This uses a Digital Elevation Model to represent the appropriate surface elevation and topography, then the surface reflectance values are adjusted accordingly."
  },
  {
    "objectID": "8_temperature_sar.html#sec-8-application",
    "href": "8_temperature_sar.html#sec-8-application",
    "title": "8  Synthetic Aperature Radar (SAR)",
    "section": "8.2 Application",
    "text": "8.2 Application\nWe have seen in the Building Spatial Applications with Big Data module that SAR can be effectively used to monitor conflict damage detection but I wanted to look at some other use cases.\nThe NASA SAR Handbook (Flores et al. (2019)) is an extremely comprehensive look at how SAR can be used for Forest Monitoring but how can this be related to an urban environment? Some of the techniques would need to be refined to identify areas of single tree or smaller tree canopy which are more common in cities. Li et al. (2019) investigated the different approaches to monitoring Urban Forestry but SAR was not specifically addressed. Li found many papers championing the use of airborne LiDAR and Very High Spatial Resolution (VHSR) imagery to accurately assess canopy cover. However the high cost and red tape involved in accessing this data is a major barrier to it’s use particularly in local government scenarios.\nNow I spent far too long wondering why SAR isn’t used specifically for canopy calculations until I found Mastro et al. (2022) who specifically investigated the use of Sentinel-1 SAR data for change detection (including urban change) but focusing on extreme events of change. This is when it finally hit me that SAR isn’t needed for general monitoring of this! We don’t a daily, weekly or even monthly update on canopy cover. We only need a at most seasonal but more likely annual recording of this during the peak growing season.\nWhy? Because urban tree canopies change gradually, making frequent updates (e.g., daily, weekly, or even monthly) unnecessary. Instead, we only need seasonal or annual assessments during peak growing seasons. Since natural changes are gradual, high-temporal SAR data isn’t required so we can rely on optical data, which can be aggregated to reduce cloud cover effects.\nThis led me to consider other practical applications for SAR in local government. One idea was pothole monitoring—a common complaint on council social media—but the scale of potholes makes them unsuitable for SAR detection. However, subsidence monitoring presents a far more viable use case. Utilising Interferometric SAR (InSAR) to monitor ground movement changes allows for accurate monitoring (Milillo et al. (2018)). This is of utmost importance considering the tunneling through London of HS2 and Crossrail which has and could cause subsidence in these areas (Figure 8.4) leading to costly repairs and legal claims.\n\n\n\nFigure 8.4: Cumulative subsidence in London between April 2011 and December 2015. Source: Milillo et al. (2018)"
  },
  {
    "objectID": "8_temperature_sar.html#sec-8-reflection",
    "href": "8_temperature_sar.html#sec-8-reflection",
    "title": "8  Synthetic Aperature Radar (SAR)",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nIt was tough to choose between Temperature or SAR topics for these week. In the end I choose SAR to round out my knowledge of both because for the group work in Building Spatial Applications with Big Data module we are focusing on temperature and specifically the Urban Heat Island effect.\nIn the case of SAR, I think there are many areas that can be explored, particularly complementing optical sensor data with SAR to detect changes in surface types over time.\nOverall I’ve really enjoyed this module and want to push Remote Sensing use in my work environment. We have touched on so many areas where I can see benefits to create consistent and reproducible analysis to help guide decision makers. Particular areas that I would like to investigate are air quality, Urban Heat Island effect and vegetation monitoring. Once confident in my research I would want to present this to London Geospatial (a group of London Borough geospatial professionals for which I am a co-founder) as an area for knowledge growth for all London Boroughs.\n\n\n\n\nFlores, Africa, K. Herndon, Rajesh Thapa, and Emil Cherrington. 2019. “Synthetic Aperture Radar (SAR) Handbook: Comprehensive Methodologies for Forest Monitoring and Biomass Estimation.” https://doi.org/10.25966/NR2C-S697.\n\n\nLi, Xun, Wendy Y. Chen, Giovanni Sanesi, and Raffaele Lafortezza. 2019. “Remote Sensing in Urban Forestry: Recent Applications and Future Directions.” Remote Sensing 11 (10, 10): 1144. https://doi.org/10.3390/rs11101144.\n\n\nMastro, Pietro, Guido Masiello, Carmine Serio, and Antonio Pepe. 2022. “Change Detection Techniques with Synthetic Aperture Radar Images: Experiments with Random Forests and Sentinel-1 Observations.” Remote Sensing 14 (14, 14): 3323. https://doi.org/10.3390/rs14143323.\n\n\nMilillo, Pietro, Giorgia Giardina, Matthew J. DeJong, Daniele Perissin, and Giovanni Milillo. 2018. “Multi-Temporal InSAR Structural Damage Assessment: The London Crossrail Case Study.” Remote Sensing 10 (2, 2): 287. https://doi.org/10.3390/rs10020287."
  }
]