[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Remote Sensing - Learning Diary",
    "section": "",
    "text": "Welcome\nThis is my learning diary for the CASA0023 Remotely Sensing Cities an Environments module. Firstly, let’s talk a bit about myself and my background."
  },
  {
    "objectID": "index.html#personal-introduction",
    "href": "index.html#personal-introduction",
    "title": "CASA0023 Remote Sensing - Learning Diary",
    "section": "Personal Introduction",
    "text": "Personal Introduction\nHi! I’m Paul and I am a part-time degree apprenticeship student. I have a strong GIS background spanning nearly 20 years but with very little working experience with remote sensing.\nMost of my working life spent has been in Local Government and I am currently the GIS Administrator for the London Borough of Camden. I have predominantly used proprietary GIS software such as MapInfo, ArcGIS and Cadcorp. In more recent years I have also been using QGIS.\nIn terms of remote sensing, myself and especially Camden are very new to how this can shape decision making and policy. In the 2023/24 we took part in an Earth Observation Pilot scheme run by the Geospatial Commission and supported by AirBus. However, at the time we did not have the necessary skills, knowledge or software to really make full use of this pilot. If only this course started a year earlier!!\nDespite this lack of knowledge, the GIS Team did manage to use some EO data to build a site suitability model for Urban Greening locations (although my personal input was limited to support and project management). The main limitation we had in using the EO data available was that the technical aspects were conducted between QGIS and ArcGIS Pro (with an advanced licence and all spatial extensions). As such the workflow is not reproducible and therefore limited to a snapshot in time especially as access to the EO data was withdraw at the end of the pilot.\nIn January 2025 Camden have been invited to take part in a new EO Data Hub pilot which will provide more constant and consistent temporal and spatial resolution data. The exact details of the products included are not yet known but should fit very nicely into the topics learnt in the Remote Sensing Cities and Environment module as well as the Building Spatial Applications with Big Data module.\nMy overall aims for this module are to be able to successfully process and analyse EO data using best practice techniques with the key being that they are reproducible techniques. These can then be used as a new decision making and policy making tool for the London Borough of Camden as this is an area that has never been explored at Camden and is rarely explored in Local Government in general."
  },
  {
    "objectID": "intro.html#sec-summary",
    "href": "intro.html#sec-summary",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nAs a relative newbie to Remote Sensing there was so much new information this week that it’s very difficult to choose even a few things to talk about without writing an whole essay. Therefore I have decided that the best way to summarise this would be through a mind map Figure 1.1.\n\n\n\nFigure 1.1: Introduction to Remote Sensing Mind map\n\n\nThere is so much information that could be discussed here but I’d like to focus on the bands. Images produced at different bands are what makes up the creation of useful and relevant images. Personally I have previously attempted to use earth observation data without understanding the differences between the bands and this made the task at hand incredibly difficult and mainly involved mindlessly following guides and videos just to get a semi-readable output. So this weeks introduction to remote sensing really helped me to understand what bands relate to which information on the ground. And importantly how the different bands can be combined depending on the purpose of any analysis."
  },
  {
    "objectID": "intro.html#sec-application",
    "href": "intro.html#sec-application",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nThere are numerous applications for remote sensing which have been discussed widely in many articles. Just by searching scholarly articles published in just the past month for the term “remote sensing”, hundreds of articles are returned. By scanning the first few pages articles ranging from fire monitoring, wheat yield prediction, military and flooding are evident. Also, the number of different landscapes that can be monitored are also highly evident, including polar regions, mountains, wetlands, cities, forests and agricultural land.\nWhilst many of the use cases available are fascinating, as this is an introduction to remote sensing it would be easy to get lost in the array of use cases on offer. As such I have instead decided to focuses on a comparison between Landsat-8 and Sentinel-2. There are still a huge amount of articles to consider in this topic, many again with very different use cases however I will consider two more general comparison articles.\n\n1.2.1 Prelimary Sentinel-2 and Landsat 8 Comparison\nDespite the many variables in sensor technology it is possible to compare imagery from Landsat-8 and Sentinel-2 due to an overlap in the bands captured by each. Mandanici and Bitelli (2016) prepared an initial comparison approximately a year after Sentinel-2 was launched in 2015. Landsat-8 was launched in 2013.\nMandanici and Bitelli begin with a basic summary of the sensor which provides useful context for their comparison which summarised in Table 1.1.\n\n\n\n\nTable 1.1: Summary comparison of basic Landsat-8 and Sentinel-2 specifications\n\n\nSatellite\nSpatialResolution\nSwathWidth\nRevisitTime\nSensor\nNumberOfBands\nComparableBands\n\n\n\n\nLandsat-8\n30m\n185km\nOperational Land Imager (OLI)\n16 days\n11\nblue: 485 nm, green: 563 nm, red: 655 nm, NIR: 865 nm, short-wave infrared 1 (SWIR1): 1610 nm, SWIR2: 2200 nm\n\n\nSentinel-2\nup to 10m\n290km\nMultispectral Instruments (MSI)\n5 days\n13\nblue: 490 nm, green: 560 nm, red: 665 nm, NIR: 842 nm, SWIR1: 1910 nm, and SWIR2: 2190 nm\n\n\n\n\n\n\n\n\nSix sites across the Earth were chosen to compare Sentinel/Landsat images, the sites were chosen to provide a mix of land cover types and climatic conditions, the comparison images were taken on the same day to build as close a comparison as possible. Correlation and regression coefficients were then calculated across the bands for the study areas.\nFrom my currently limited remote sensing knowledge I found this methodology difficult to follow due to it’s highly mathematical model, however the overall results showed there was a very good correlation between the corresponding bands. Although limitations were identified including radiometric differences requiring careful evaluation and investigating discrepancies in reflectance values relevance.\n\n\n1.2.2 Comparison using Google Earth Engine\nThe article by Nasiri et al. (2022) was chosen due to it’s more contemporary nature providing a useful and relevant comparison against the preliminary comparison. A further advantage of reviewing this research was it’s methodology of using Google Earth Engine (GEE). We will begin using Google Earth Engine later in the course so it seemed even more appropriate to use this paper.\nThe specific methodology for comparing Landsat-8 and Sentinel-2 involved producing time-series analysis of a single study area (Tehran Province, Iran) using images from both satellites. As the resolutions did not match the MSI data was downsampled to the match that of OLI.\nThe first output was a range of comparison images Figure 1.2 which help demonstrate how difficult it is for the human eye to identify variations in accuracy of this level of data.\n\n\n\nFigure 1.2: Landsat-8 and Sentinel-2 image comparison - using False-colour images (R: NIR, G:red, B: green) across seasons: (a) Spring, (b) Summer and (c) Autumn\n\n\nThe second output was more in-depth evaluation\n\n\n1.2.3 Review\nDespite lacking some knowledge around the specific calculations in the analysis and found these to be two very interesting articles. The comparison between the methodologies is quite clear with Nasiri et al. (2022) being easier to follow mainly due to it’s use of more visual representation of the data.\nThe methodology for Mandanici and Bitelli (2016) appears to be a lot less reproducible as there is less detail in this section, it also does not refer to which languages, applications, etc. that were used. Nasiri on the otherhand was more reproducible due to it’s use of Google Earth Engine which has the added bonus of avoiding local storage issues and providing greater computing power for analysis and processing (Carrasco et al. 2019). This may just be due to the fact that Google Earth Engine wasn’t as widely used or known in 2016 as it is was 2022.\nThe main limitations I see with both articles if that the number of samples used was quite low and therefore it cannot be said with absolute certainty whether the results would be replicated in other areas. Mandanici does look at multiple sites but they are chosen for their differing landscapes and climate. Nasiri on the other hand only uses one sample area but with clearly distinguished land uses, Whilst this is useful as it identified variations in accuracy across land uses (artificial land 95-100%, bare earth 71-86%) it is not clear whether similar results would be expected in other areas of interest."
  },
  {
    "objectID": "intro.html#sec-refection",
    "href": "intro.html#sec-refection",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nBoth articles discussed in Section 1.2 provide a good overview of both Landsat-8 and Sentinel-2 which helps to consolidate some of the topics taught in class this week. Especially in relation to how different bands can be used for different purposes. This will be extremely useful in the coming months as we look at our own analysis in this course and in CASA0025, but also as part of work as we begin to use a new Earth Observation Data Hub.\nSome of the methodology of both papers is still difficult for me to process, particularly around the specific analysis and calculations, but hopefully this is because it is still the first week of remote sensing. However reading these articles really helped my understanding of the use cases of both satellites and specifically their similiarities and importantly how the spectral resolution of the same bands have slight variations to be aware of. Also understanding how bands, can be combined in different ways and in different applications to produce similar images for analysis. This then helps to provide even more comparable images across a larger temporal scale as any gaps in imagery (possibly due to constraints such as scattering and in particular cloud cover) from one satellite may be able to be filled by the other.\nAnother topic I would have liked to explore is the effect that different types of scattering has on the images captured and how any pre-processing by the agencies responsible for the data affects the images that we see.\n\n\n\n\nCarrasco, Luis, Aneurin W. O’Neil, R. Daniel Morton, and Clare S. Rowland. 2019. “Evaluating Combinations of Temporally Aggregated Sentinel-1, Sentinel-2 and Landsat 8 for Land Cover Mapping with Google Earth Engine.” Remote Sensing 11 (3, 3): 288. https://doi.org/10.3390/rs11030288.\n\n\nMandanici, Emanuele, and Gabriele Bitelli. 2016. “Preliminary Comparison of Sentinel-2 and Landsat 8 Imagery for a Combined Use.” Remote Sensing 8 (12, 12): 1014. https://doi.org/10.3390/rs8121014.\n\n\nNasiri, Vahid, Azade Deljouei, Fardin Moradi, Seyed Mohammad Moein Sadeghi, and Stelian Alexandru Borz. 2022. “Land Use and Land Cover Mapping Using Sentinel-2, Landsat-8 Satellite Images, and Google Earth Engine: A Comparison of Two Composition Methods.” Remote Sensing 14 (9, 9): 1977. https://doi.org/10.3390/rs14091977."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Carrasco, Luis, Aneurin W. O’Neil, R. Daniel Morton, and Clare S.\nRowland. 2019. “Evaluating Combinations of\nTemporally Aggregated Sentinel-1, Sentinel-2\nand Landsat 8 for Land Cover Mapping with\nGoogle Earth Engine.” Remote Sensing 11 (3,\n3): 288. https://doi.org/10.3390/rs11030288.\n\n\nMandanici, Emanuele, and Gabriele Bitelli. 2016. “Preliminary\nComparison of Sentinel-2 and\nLandsat 8 Imagery for a Combined\nUse.” Remote Sensing 8 (12, 12): 1014. https://doi.org/10.3390/rs8121014.\n\n\nNasiri, Vahid, Azade Deljouei, Fardin Moradi, Seyed Mohammad Moein\nSadeghi, and Stelian Alexandru Borz. 2022. “Land Use\nand Land Cover Mapping Using Sentinel-2, Landsat-8\nSatellite Images, and Google Earth Engine: A\nComparison of Two Composition Methods.”\nRemote Sensing 14 (9, 9): 1977. https://doi.org/10.3390/rs14091977."
  },
  {
    "objectID": "2_portfolio.html",
    "href": "2_portfolio.html",
    "title": "2  Portfolio",
    "section": "",
    "text": "This week we discussed how to build our online portfolio using Quarto (web page) and Xarigan (presentation). This also included how to host pages through GitHub.\nOur main task this week was to build a presentation in Xarigan about a specific remote sensing satelitte.\nI choose to create my presentation on the commercial satellite, Pleiades Neo, as I have a working knowledge of the imagery produced."
  },
  {
    "objectID": "3_data_corrections.html#sec-summary",
    "href": "3_data_corrections.html#sec-summary",
    "title": "3  Remote Sensing Data and Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nThis week we delved deeper into remote sensing topics particularly data corrections, joining and enhancements. Lots of new terms were raised and some of the concepts were challenging to understand so it’s easiest to summarise these terms by building a ?tbl-remote-sensing-glossary. A lot of these terms could have entire lectures dedicated to them so I attempt to put these into a simple terms as possible. Due to the large number of terms considered, ChatGPT was used to provide an initial sweep of terms and sources, then these were fact checked and more detail added where necessary. Sources include NASA, ESA, USGS, Landsat Science, ESRI and many of the sources listed in the references.\n\n\n\n\nTable 3.1: Glossary of remote sensing terminology\n\n\nTerm\nDescription\n\n\n\n\nRBV sensor\nReturn Beam Vidicon - A camera-based sensor used on early Landsat missions for capturing panchromatic images.\n\n\nMSS sensor\nMultispectral Scanner - The sensor onboard early Landsat satellites that captured data in several broad spectral bands.\n\n\nPush broom\nA type of sensor that uses linear arrays to capture imagery as the platform moves forward, capturing a swath in one go.\n\n\nWhisk broom\nA sensor that uses a mirror to scan the ground cross-track while capturing data one pixel at a time.\n\n\nScan Line Corrector\nDevice that compensates for motion distortions in satellite imagery caused by satellite movement.\n\n\nGeometric Correction\nThe process of correcting spatial distortions in remote sensing imagery to align with map coordinates. This is a similar process to that of paper maps being digitised and corrected to align with digitial representation of the Earth. It involves the use of ground control points identified on the captured image and a \"gold standard\" image, then using transformation algorithms to align the image.\n\n\nAtmospheric Correction\nRemoving the atmospheric effects (e.g., scattering, absorption) from data values to retrieve the surface reflectance. It is always recommended to use atmospheric correction as this removes hazing from images.\n\n\nDark Object Subtraction (DOS)\nA technique for atmospheric correction that finds the values of the darkest values and then subtracts the that from each pixel. Could also be termed hostogram adjustment.\n\n\nPseudo-invariant features (PIF)\nFeatures assumed to have stable reflectance over time. Examples include water bodies, rocky surfaces. Can be used for atmospheric correction, sensor callibration and change detection\n\n\nAtmospheric Radiative Transfer Models\nMathematical models used to simulate the interaction of light with the atmosphere. Commercial software available for atmospheric correction includes ACORN (Atmospheirc CORrection Now), FLAASH (Fast Line-of-Sight Atmospheric Analysis of Spectral Hypercubes), QUAC (Quick Atmospheric Correction) and ATCOR (Atmospheric Correction of Reflectance). Free software: SMAC (Simplified Model for Atmospheric Correction and Orfeo Toolb\n\n\nEmpirical Line Correction\nA method of atmospheric correction using ground-truth measurements to directly relate image data to reflectance values.\n\n\nField Spectrometer\nPortable instruments used to measure the spectral reflectance of materials in situ.\n\n\nPath Radiance\nThe portion of radiance reflected by the atmosphere e.g. scattering.\n\n\nAtmospheric attenuation\nThe atmospheric absorption of electromagnetic radiation due to materials in the atmosphere (e.g. water vapour, dust)\n\n\nOrthorectification or Topographic correction\nCorrecting distortions in imagery, making the pixels appear at nadair\n\n\nNadir / off-nadir\nNadir: directly beneath a sensor. Off-nadir: any angle except directly beneath the sensor.\n\n\nSolar Zentih\nThe angle between the sun and the vertical direction at a given location.\n\n\nSolar Azimuth\nThe angle of the sun, measured clockwise from the north. North = 0°, East = 90° at sunrise and 270° at sunset\n\n\nRadiometric Callibration\nThe process of converting the captured Digital Number to a radiance or reflectance values.\n\n\nDigital Number (DN)\nThe raw output value (with no units) recorded by a sensor, wuth each number indicating a range of colours, e.g. an 8 bit image has value 0 (black) to 255 (white). These represent the radiance or reflectance.\n\n\nRadiance\nRadiation that is leaving the Earth\n\n\nSurface Reflectance\nThe fraction of incoming light that a surface reflects, corrected to account for atmospheric effects and light source.\n\n\nIrradiance\nRadiation that is reaching the Earth such as from the Sun\n\n\nMosiacking\nThe process of combining multiple images into a single and seamless image.\n\n\nContrast Enhancement\nTechniques used to improve image visibility by increasing the contrast between features.\n\n\nBand ratioing\nDividing the pixel values of one spectral band by another to highlight specific features (e.g., vegetation indices).\n\n\nFiltering\nThe process of enhancing or suppressing specific spatial frequencies in an image.\n\n\nEdge enhancement\nTechniques to highlight boundaries and transitions in imagery.\n\n\nEmbossing\nAn image processing technique that simulates 3D surface relief.\n\n\nPrincipal Comonent Analysis (PCA)\nA statistical technique used to transform multi-spectral data by reducing the dimensions of the data whilst retaining the key information.\n\n\nTexture\nThe spatial variation in pixel values, representing surface roughness or pattern.\n\n\nImage fusion\nA subset of data fusion that focuses on merging images to improve resoluton. This can be used to combine certain Landsat and Sentinel images into a single working image.\n\n\nPan Sharpen\nA technique used to enhance the spatial resolution of multispectral images by combining them with a high resolution panchromatic image.\n\n\nData fusion\nThe process of combining data from multiple sources with the goal of improving accuracy and usefulness.\n\n\n\n\n\n\n\n\nAnother key point raised throughout the lecture was that regression plays a key part in many of the corrections that we looked into. This links back to the (wk1-applications?) discussion were I initially found it difficult to understand some of the comparisons that were being made. So this lecture really helped to consolidate those comparison by clearly explaining the important role that regression plays in remote sensing."
  },
  {
    "objectID": "3_data_corrections.html#sec-applications",
    "href": "3_data_corrections.html#sec-applications",
    "title": "3  Remote Sensing Data and Corrections",
    "section": "3.2 Applications - Effectiveness of relative and absolute correction",
    "text": "3.2 Applications - Effectiveness of relative and absolute correction\nThere is almost endless possibilities to expand on in the topics covered this week so it’s a difficult job to focus on any one area. However, in week 1 I said that I’d like to investigate was atmospheric scattering therefore I will focus this section on atmospheric correction but also comparing against radiometric normalisation. This specifically looks at the differences and inaccuracy of relative and absolute correction.\n\n3.2.1 (bernando2016?)\nThe availability of absolute atmospheric correction inputs can be generalised over an area or season leading the potential accuracy issues. This is why Bernardo et al. (2016) investigated the effectiveness of an absolute atmospheric correction against a relative radiometric normalisation. Their study was specifically to estimate total suspended matter (TSM) concentrations in the Barra Bonita Hydroelectric Reservior, São Paulo however the general methodology could potentially be applied to other areas.\nThe reflectance errors were measured compared by assessing root mean squared error (RMSE) and the mean absolute percent error (MAPE). With a comparison made agaisnt the FLAASH (absolute method) against IRMAD - iteratively reweighted multivariate alteration detection (relative method) correction methods.\n\n\n\n\nTable 3.2: Reflectance errors from FLAASH and IRMAD corrections (bernando2016?)\n\n\nOLI band\nRMSE (%) FLAASH\nRMSE (%) IRMAD\nMAPE (%) FLAASH\nMAPE (%) IRMAD\n\n\n\n\nCoastal (440nm)\n133.45\n31.22\n131.45\n25.82\n\n\nBlue (480nm)\n53.70\n25.06\n51.73\n21.84\n\n\nGreen (560nm)\n11.50\n12.29\n9.61\n9.46\n\n\nRed (655nm)\n34.45\n20.03\n33.38\n16.98\n\n\nNIR (865nm)\n88.29\n49.97\n81.71\n45.37\n\n\n\n\n\n\n\n\nThe findings clearly show greater levels in inaccuracy from the absolute method (FLAASH) in both methods of comparison across nearly all bands. The only exception is the Green band’s RMSE percentage using the relative method (IRMAD). The percentage difference in correction methods for the coastal band of 131-133% (absolute) versus 25-31% (relative) is a staggering figure. It would have been really interesting to see other examples of this analysis to see if this is a general trend or just an anomaly for the area.\nThe authors do state various limitations to their study including the assumptions made in each methods potentially leading to errors themselves. This could be a good area for further investigations but what I’d really like to see is a similar paper comparing these methods in various locations to identify whether this is a general trend.\n\n\n3.2.2 Hu et al. (2011)\nWe have seen one example of a comparison between absolute and relative corrections but we shouldn’t just accept one study’s conclusion. We need to be more critical and if we can’t question findings ourselves through our own study then we can use other articles to help challenge or support these findings.\nSo I have picked a similar study with a similar methodology in Hu et al. (2011). I will focus on the key differences in the methodology but first let’s summarise the similarities:\n\ncompares using landsat images\ncompares a single study area using time series images\nuses FLAASH for absolute atmospheric correction\nuses multivariate alternative detection (MAD) for relative radiometric normalisation\n\nAlthough the use of MAD is similar to (bernando2016?)’s technique of iteratively reweighted MAD (IRMAD), it provides a more basic detection of change as it is a one-pass approach and does not iteratively refine the results, also IRMAD are much less noisy than MAD((nielson2005?), (nielson2007?)). There is also a third approach, regularised IRMAD which can perform even better but this was not part of the studies being compared.\nDespite the differences in the relative correction calculations we can still review the results to help our comparison. Hu et al. (2011) used regression to assess the difference between absolute and relative corrections and the findings can be reviewed through the standard deviation results of each method.\n\n\n\n\nTable 3.3: Standard Deviation of the difference in each band for relative normalisation against atmospheric correction\n\n\nBand\nBand 1\nBand 2\nBand 3\nBand 4\nBand 5\nBand 7\n\n\n\n\nSTD of Relative Normalization\n0.0013\n0.0018\n0.0017\n0.0045\n0.0066\n0.0047\n\n\nSTD of Atmospheric Correction\n0.0025\n0.0030\n0.0033\n0.0086\n0.0083\n0.0074\n\n\n\n\n\n\n\n\nThe overall results show that both methods reduce radiometric distortion, but relative normalisation corrects it more effectively. This is shown by the lower standard deviations of relative normalisation versus atmospheric correction across all bands (?tbl-std-comparison).\n\n\n3.2.3 Review\nI suspect that whilst the papers talk about absolute corrections having high percentage error in certain bands that this could be specific to the location of the study and the assumptions made throughout. There are so many variables at play that it would be highly improbable to produce a study that could feasible review all of these aspects.\nIn an ideal world we would be able to say exactly what corrections and enhancements to apply to an image to provide the optimal output. However that is just not possible, if we think about the sheer amount of variables, including atmospheric conditions, topological factors, sensor differences, then we can begin to see why there is no simple set of tools for analysis.\nThis is evident in both the papers discussed and have previously seen in other papers. It could appear that the scope is quite limited as they focus on very small samples (Bernando - Barra Bonita Hydroelectric Reservior area, São Paulo; Hu et al - Yellow River Source, Eastern Tibet) for their analysis (previously discussed in week 1). However if we consider this from a technical point of view then simply the amount of computational power required to process much larger samples is very restrictive and time-consuming."
  },
  {
    "objectID": "3_data_corrections.html#sec-refection",
    "href": "3_data_corrections.html#sec-refection",
    "title": "3  Remote Sensing Data and Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nBefore reflecting on some of the more technical aspects discussed I think it’s first important to highlight the role that Virginia Norwood played in modern remote sensing. This was covered right at the beginning of the lecture and is quite an interesting story. A whole review could written about this but I think the fact the Virginia Norwood is known as the “mother of Landsat” says a great deal, and the full story of her life can be found in multiple articles including McClain (2023) and (inventorshallofhame2025?).\nSo back to the reflection, this week was definitely challenging, particularly with the amount of different terms, ideas and formulas raised. However when I really began to delve deeper into these concepts and particularly those discussed in Section 3.2 they really become clearer. You can really start to see the benefit these corrections and enhancements can have as part of wider studies.\nAs mentioned previously I’m looking forward to putting this ideas into practice through the Earth Observation Data Hub pilot scheme that Camden will soon have access to. I want to explore what data we will get access to and can finally understand the differences between products and particular what information can be derived from different bands. This will be a big improvement in the previous EO work that I’ve done which involved blindly following guides to try to get a result that seems similar.\nOne final note, even though it’s good to understand the processing required and it really helped boost my overall understanding of the challenges with remote sensing data, I’m so glad that most of the processing is already built into packages or in the Analysis Ready Data.\n\n\n\n\nBernardo, Nariane, Fernanda Watanabe, Thanan Rodrigues, and Enner Alcântara. 2016. “An Investigation into the Effectiveness of Relative and Absolute Atmospheric Correction for Retrieval the TSM Concentration in Inland Waters.” Modeling Earth Systems and Environment 2 (3): 114. https://doi.org/10.1007/s40808-016-0176-9.\n\n\nHu, Yong, Liangyun Liu, Lingling Liu, and Quanjun Jiao. 2011. “Comparison of Absolute and Relative Radiometric Normalization Use Landsat Time Series Images.” In MIPPR 2011: Remote Sensing Image Processing, Geographic Information Systems, and Other Applications, edited by Faxiong Zhang and Faxiong Zhang, 8006:800616. SPIE / International Society for Optics and Photonics. https://doi.org/10.1117/12.902076.\n\n\nMcClain, Dylan Loeb. 2023. “Virginia Norwood, ‘Mother’ of Satellite Imaging Systems, Dies at 96.” The New York Times: Science, April 12, 2023. https://www.nytimes.com/2023/04/12/science/space/virginia-norwood-dead.html."
  }
]